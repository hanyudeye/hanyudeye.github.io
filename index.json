[{"categories":[""],"contents":"Responsive HTML video is a web standard again, and with recent patches to Firefox (oh hey!) and Chrome that match Safari’s preexisting support, it now works across all modern browsers! That means you can use media queries for delivering your videos and potentially save your users some precious bytes.\n响应式HTML视频再次成为网络标准，最近Firefox的补丁（哦，嘿！）和Chrome，符合Safari的预先存在的支持，它现在工作在所有现代浏览器！这意味着您可以使用媒体查询来交付视频，并可能为用户节省保存一些宝贵的字节。\nAs I’ve noted in prior articles, this is great news for web performance fans, as video is by far the heaviest type of media used on websites (the median weight of just the video files on pages that use video is almost 5 megabytes per page on mobile devices), and that weight has a huge impact on performance, users’ data costs, sites’ hosting costs, and overall energy usage. Using an HTML video element to display a static video file is one of the most common and portable ways to drop a video into a webpage today, so it’s great we now have options to do it more responsibly.\n正如我在之前的文章中所指出的，这对Web性能粉丝来说是个好消息，因为视频是目前为止网站上使用的最重的媒体类型（仅使用视频的页面上的视频文件的平均重量在移动的设备上几乎是每页5 MB），并且该重量对性能，用户的数据成本，网站的托管成本和整体能源使用有巨大的影响。使用HTML视频元素来显示静态视频文件是当今将视频放入网页的最常见和最便携的方法之一，所以我们现在可以更负责任地选择这样做。\nIf you haven’t yet caught up on how responsive video works, I’d recommend reading How to Use Responsive Video (…and Audio!) first as a primer, because it’s loaded with examples of how to use it and also when to consider alternatives, like HTTP Live Streaming.\n如果你还没有了解响应式视频是如何工作的，我建议你阅读如何使用响应式视频（.和音频！）首先作为入门，因为它加载了如何使用它的示例，以及何时考虑替代方案，如HTTP Live Streaming。\nWhat You’ll Learn Today… 今天你会学到什么…\nIn this post, I’m going to talk briefly about responsive video, but most of the post will be about using HTML web components to extend native video behavior in very helpful ways. But even if you’re not particularly interested in video development, stick around as I’ll demonstrate how to build an HTML Web Component to progressively enhance anything you need.\n在这篇文章中，我将简要地讨论响应式视频，但大部分内容都是关于使用HTML Web组件以非常有用的方式扩展原生视频行为。但是，即使您对视频开发不是特别感兴趣，也可以继续阅读，因为我将演示如何构建HTML Web组件来逐步增强您所需要的任何内容。\nHow Responsive Video Works (…and doesn’t) 响应式视频如何工作（\u0026hellip;\u0026hellip;和不工作）\nTo start, let’s recap what responsive video is. I’ll start with some example HTML and then explain what we’re looking at…\n首先，让我们回顾一下什么是响应式视频。我将从一些示例HTML开始，然后解释我们正在看的内容。\n1 2 3 4 \u0026lt;span\u0026gt;\u0026amp;lt;video\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;lt;source\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;src\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;/sandbox/video-media/small.mp4\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;media\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;(max-width: 599px)\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;lt;source\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;src\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;/sandbox/video-media/large.mp4\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;lt;/video\u0026amp;gt;\u0026lt;/span\u0026gt; That’s a basic responsive video element. It’s responsive because one of the source elements has a media attribute on it that includes a media query, making its source selection conditional to the browser’s viewport size. If you’ve used the picture element before, that media attribute is going to look familiar, because picture was actually designed based on how this works in HTML video (back when responsive video was supported the first time around, which is a long story).\n这是一个基本的响应式视频元素。它是响应式的，因为其中一个 source 元素上有一个包含媒体查询的 media 属性，使其源选择取决于浏览器的视口大小。如果你以前使用过 picture 元素，那么 media 属性看起来会很熟悉，因为 picture 实际上是基于HTML video 中的工作原理设计的（回到第一次支持响应式视频的时候，这是一个很长的故事）。\nHere’s that video element live in the page. The latest versions of common browsers will see a video that says “small video source” at small viewport sizes and a video that says “large video source” at wider viewport sizes. Unsupporting, older browsers will simply select the first source suitable they find (small.mp4 in this case) because those browsers ignore the media attribute and pick the first source that matches, ignoring any that come after it.\n这是页面中的 video 元素。最新版本的普通浏览器将看到一个视频，说“小视频源”在小视口大小和一个视频，说“大视频源”在更宽的视口大小。不支持，旧的浏览器将简单地选择他们找到的第一个合适的源（在这种情况下是small.mp4），因为这些浏览器忽略了媒体属性，并选择匹配的第一个源，忽略它之后的任何源。\nSo that’s the basics of how a responsive video element works.\n这就是响应式视频元素的基本工作原理。\nHow It Doesn’t Work 如何不工作\nOne thing that folks (me included!) tend to find surprising about responsive video is that unlike other “responsive” features in web design–CSS Media Queries or the picture element for example–responsive video sources are only assessed once, when the video (and typically the entire page) first loads.\n有一件事是人们（包括我在内！）关于响应式视频，一个令人惊讶的发现是，与网页设计中的其他“响应式”功能（例如CSS媒体播放器或 picture 元素）不同，响应式视频源仅在视频（通常是整个页面）首次加载时评估一次。\nThat means that while you’ll still enjoy the performance benefits of an appropriately selected source at page load, it won’t be reassessed after page load when media conditions change (when, for example, when the user resizes their browser window). It’s entirely possible that could change one day, but there are a number of reasons this behavior was not included in the initial implementation, such as complications involved in syncing up the timecode after a source is swapped, as well as the reasonable goal of matching the behavior of the existing implementation in Safari.\n这意味着，虽然您仍然可以在页面加载时享受适当选择的源的性能优势，但在页面加载后，当媒体条件发生变化时（例如，当用户调整浏览器窗口大小时），它不会重新评估。这完全有可能在某一天发生变化，但是有很多原因导致这种行为没有包括在最初的实现中，例如在交换源代码后同步时间码所涉及的复杂性，以及匹配Safari中现有实现的行为的合理目标。\nRegardless of all that, folks are right to find this part of the feature a little… unexpected.\n不管这一切，人们是正确的发现这一部分的功能有点.意外。\nWhich got me thinking, what would it take to make that behavior work on top of what we already have in browsers today?\n这让我想到，在我们今天已经拥有的浏览器之上，需要什么才能让这种行为发挥作用？\nLet’s find out. 让我们来看看。\nExtending Video with an HTML Web Component 使用HTML Web组件扩展视频\nWeb Components are having a moment right now, and particularly, “HTML Web Components”, which is a term being used to describe web components that add behavior to regular old HTML by wrapping it in a custom element and applying a little JavaScript to enhance that markup further.\nWeb组件现在有一个时刻，特别是“HTML Web组件”，这是一个术语，用于描述通过将其包装在自定义元素中并应用一点JavaScript来进一步增强标记的方式向常规旧HTML添加行为的Web组件。\nAn HTML Web Component is an ideal tool for extending the functionality of standard HTML, like say, a video element for example! I’m going to walk through how I built one that’ll make responsive video even responsiver, so it reacts to media changes after page load, should they occur.\nHTML Web组件是扩展标准HTML功能的理想工具，例如，视频元素！我将介绍我如何构建一个可以使响应式视频更加响应的视频，以便在页面加载后对媒体更改做出反应。\nFirst, a Custom Element 第一，自定义元素\nTo start, we will need a custom element, which is just an HTML element that you invent that has at least one dash in its name. I’ll go with responsive-video, like this:\n首先，我们需要一个自定义元素，它只是一个您创建的HTML元素，其名称中至少有一个破折号。我会用 responsive-video ，像这样：\n1 \u0026lt;span\u0026gt;\u0026amp;lt;responsive-video\u0026amp;gt;\u0026amp;lt;/responsive-video\u0026amp;gt;\u0026lt;/span\u0026gt; Nice. So that’s a custom element, and with a little added JavaScript it could become a web component. But in order to make it an “HTML Web Component,” we’ll want to wrap that component around some HTML that is already meaningful and functional on its own, such as our video element above.\n不错啊所以这是一个自定义元素，加上一点JavaScript，它就可以成为一个Web组件。但是为了使它成为一个“HTML Web组件”，我们需要将该组件包装在一些已经有意义和功能的HTML上，例如上面的 video 元素。\nHere’s that video element wrapped in a responsive-video custom element.\n下面是包装在 responsive-video 自定义元素中的 video 元素。\n1 2 3 4 5 6 \u0026lt;span\u0026gt;\u0026amp;lt;responsive-video\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;lt;video\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;controls\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;autoplay\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;loop\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;lt;source\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;src\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;/sandbox/video-media/small.mp4\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;media\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;(max-width: 599px)\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;lt;source\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;src\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;/sandbox/video-media/large.mp4\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;lt;/video\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;lt;/responsive-video\u0026amp;gt;\u0026lt;/span\u0026gt; That’s about it for the HTML part of this article. Based on what I’ve done so far, browsers will just ignore that custom element, (though you can style it with CSS already if you want to).\n这就是本文HTML部分的内容。根据我到目前为止所做的，浏览器将忽略该自定义元素，（尽管如果你想的话，你已经可以用CSS来设计它了）。\nTo get browsers to recognize this as an element with its own unique properties and behavior, you’ll need to write a web component in JavaScript. Let’s do that.\n要让浏览器将其识别为具有自己独特属性和行为的元素，您需要用JavaScript编写一个Web组件。那就这么办吧\nAdding the JavaScript 添加JavaScript To enhance this HTML, we’ll create and load a JavaScript module that will contain our web component code. That code will live in a new file called responsivevideo.js.\n为了增强这个HTML，我们将创建并加载一个包含Web组件代码的JavaScript模块。该代码将存在于名为 responsivevideo.js 的新文件中。\nPlease note the last line of the code below to see how we can import that script into our page:\n请注意下面代码的最后一行，看看我们如何将该脚本导入到我们的页面中：\n1 2 3 4 5 6 7 \u0026lt;span\u0026gt;\u0026amp;lt;responsive-video\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;lt;video\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;controls\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;autoplay\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;loop\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;lt;source\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;src\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;/sandbox/video-media/small.mp4\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;media\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;(max-width: 599px)\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;lt;source\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;src\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;/sandbox/video-media/large.mp4\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;lt;/video\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;lt;/responsive-video\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;lt;script\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;type\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;module\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;src\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;responsivevideo.js\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;gt;\u0026amp;lt;/script\u0026amp;gt;\u0026lt;/span\u0026gt; Now let’s look at the code we’ll put inside that file.\n现在让我们看看我们将放在该文件中的代码。\nWriting the Web Component Logic 编写Web组件逻辑\nWeb Components are designed for Progressive Enhancement. They come with a series of lifecycle events that are incredibly helpful for applying behavior to elements at moments such as when they’re created or when they’re appended to the DOM, and also for removing behavior and event handlers when an element is removed from the DOM or destroyed altogether.\nWeb组件是为渐进式增强而设计的。它们附带了一系列生命周期事件，这些事件对于在创建元素或将元素附加到DOM时将行为应用于元素以及在从DOM中删除元素或完全销毁元素时删除行为和事件处理程序非常有用。\nBefore we get ahead of ourselves on that, let’s start with some boilerplate code for our responsive-video component.\n在我们开始之前，让我们先从 responsive-video 组件的样板代码开始。\n1 2 \u0026lt;span\u0026gt;class\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;ResponsiveVideo\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;extends\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;HTMLElement\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; customElements\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;define\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;responsive-video\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;,\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;ResponsiveVideo\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt; That’s not a lot of code, but it is already doing a lot of work. To start, it defines a class called ResponsiveVideo, which extends the HTMLElement class, which is the same class that all standard HTML elements–you know, \u0026lt;p\u0026gt;, \u0026lt;select\u0026gt;, \u0026lt;input\u0026gt;, etc.–use for their own behavior in the browser. After that, we’re using customElements.define to actually define a new HTML element (the tag part) called \u0026lt;responsive-video\u0026gt; that will inherit the class’s logic and behavior.\n这不是很多代码，但它已经做了很多工作。首先，它定义了一个名为 ResponsiveVideo 的类，它扩展了 HTMLElement 类，这个类是所有标准HTML元素（如 \u0026lt;p\u0026gt; 、 \u0026lt;select\u0026gt; 、 \u0026lt;input\u0026gt; 等）在浏览器中用于其自身行为的同一个类。之后，我们使用 customElements.define 来实际定义一个名为 \u0026lt;responsive-video\u0026gt; 的新HTML元素（标记部分），它将继承类的逻辑和行为。\nSo now we have a Web Component, but it’s still not doing anything. Inside our class, we can start to use those lifecycle events I had mentioned to add (and remove) behavior and event handlers to the HTML at appropriate moments. I recommend reading up on all of the features of web components, but for the purpose of this article I’ll cover just a few lifecycle events that are relevant to adding the behavior we want:\n所以现在我们有了一个Web组件，但它仍然没有做任何事情。在我们的类中，我们可以开始使用我提到的那些生命周期事件来在适当的时候向HTML添加（和删除）行为和事件处理程序。我建议您阅读Web组件的所有功能，但出于本文的目的，我将只介绍一些与添加我们想要的行为相关的生命周期事件：\nconstructor 构造函数 connectedCallback disconnectedCallback 已断开回调 The Constructor 构造函数 The constructor of a web component is called when an instance of its HTML element is created. It’s useful for establishing some upfront variables within the element that’ll be useful to later events and internal logic. It’s often not the best place for all of our initialization code though because when the constructor is called, the element may not be appended to the DOM quite yet, so the many conditions relating to the page around it or even inside it won’t yet be accessible.\nWeb组件的 constructor 在创建其HTML元素的实例时被调用。它对于在元素中建立一些前期变量很有用，这些变量对后面的事件和内部逻辑很有用。它通常不是我们所有初始化代码的最佳位置，因为当构造函数被调用时，元素可能还没有被追加到DOM中，因此与它周围甚至内部页面相关的许多条件还无法访问。\nHere’s our code with a constructor call added:\n下面是添加了构造函数调用的代码：\n1 2 3 4 5 6 7 \u0026lt;span\u0026gt;class\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;ResponsiveVideo\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;extends\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;HTMLElement\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;constructor\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;()\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;super\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;();\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; console\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;log\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; customElements\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;define\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;responsive-video\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;,\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;ResponsiveVideo\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt; Inside the constructor, I started by calling super(). Generally, it’s advised that we include this step first because it allows the component to gain access to the base class’s (that is, HTMLElement) properties. Just after the super(), I’m logging this to the browser console, which refers to the HTML element we’re enhancing.\n在构造函数中，我首先调用 super() 。一般来说，建议我们首先包括这一步，因为它允许组件访问基类（即 HTMLElement ）的属性。在 super() 之后，我将 this 登录到浏览器控制台，它指的是我们正在增强的HTML元素。\nIf you were to check the browser console at this point, you would see that the HTML element itself was logged: “responsive-video”\n如果您在此时检查浏览器控制台，您将看到HTML元素本身被记录：“responsive-video”\nFor now, I won’t use the constructor for anything, but in my final component I am going to use it to define some upfront variables that other events and methods will use.\n现在，我不会使用构造函数来做任何事情，但在我的最后一个组件中，我将使用它来定义一些其他事件和方法将使用的前期变量。\nUsing connectedCallback \u0026amp; disconnectedCallback 使用connectedCallback和disconnectedCallback\nNext, I’ll use some special lifecycle events to apply behavior to any responsive-video element when it is added to the DOM, and also remove behavior when/if it’s ever removed from the DOM. It’s worth pointing out here that in contrast to the days when we needed to wait for “DOM Ready” to query the DOM for elements to make our enhancements, these events are a major upgrade!\n接下来，我将使用一些特殊的生命周期事件，在任何 responsive-video 元素被添加到DOM时将行为应用于该元素，并在它从DOM中删除时删除行为。这里值得指出的是，与我们需要等待“DOM Ready”来查询DOM元素以进行增强的日子相比，这些事件是一个重大的升级！\nI know I’m going to use these two events, so first I’ll add them with some console logs to show how they look.\n我知道我将使用这两个事件，所以首先我将添加它们和一些控制台日志，以显示它们的外观。\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;span\u0026gt;class\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;ResponsiveVideo\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;extends\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;HTMLElement\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;constructor\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;()\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;super\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;();\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;// upfront variables will go here\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; connectedCallback\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(){\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; console\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;log\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;`${this} is in the DOM`\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; disconnectedCallback\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(){\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; console\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;log\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;`${this} has been removed from the DOM`\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; customElements\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;define\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;responsive-video\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;,\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;ResponsiveVideo\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt; Above, we’re logging to the browser console whenever a responsive-video element shows up in the DOM (including when the page first loads), and whenever one is removed from the DOM.\n在上面的例子中，每当 responsive-video 元素出现在DOM中时（包括页面首次加载时），以及每当从DOM中删除时，我们都会记录到浏览器控制台。\nconnectedCallback is a good place to create useful references to elements inside my component. For example, many of my methods will reference the video element inside the component, so I can make a reference to it inside connectedCallback like so, using this.querySelector to search within the scope of the component itself instead of the entire document.\nconnectedCallback是一个很好的地方来创建对组件内元素的有用引用。例如，我的许多方法将引用组件内部的 video 元素，因此我可以像这样在 connectedCallback 中引用它，使用 this.querySelector 在组件本身的范围内搜索，而不是整个文档。\n1 2 3 \u0026lt;span\u0026gt;connectedCallback\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(){\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;video \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;querySelector\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;video\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt; With these handy methods, we now have the tools we need to add some logic.\n有了这些方便的方法，我们现在就有了添加一些逻辑所需的工具。\nAdding Custom Behavior 添加自定义行为 The rest of our component’s code will serve one purpose: instructing the video element to select and load a new, appropriate source for the video element whenever/if media conditions change in a way that’s relevant to its source elements.\n我们组件的其余代码将用于一个目的：指示 video 元素为视频元素选择和加载一个新的，适当的源，无论何时/如果媒体条件以与其 source 元素相关的方式发生变化。\nTo do that, we’ll write some code that applies this general flow:\n为此，我们将编写一些应用此通用流程的代码：\nFind all of the source elements inside the video that have media attributes, and pass those media attribute values (which will be media queries or types) to matchMedia, which we can use to start listening to the media queries for relevant changes. Once listening, matchMedia‘s “change” event will fire whenever those media queries start or stop matching the media conditions of the browser, which can happen when a user resizes their browser to a different size, for example.\n找到 video 中所有具有 media 属性的 source 元素，并将这些媒体属性值（将是媒体查询或类型）传递给 matchMedia ，我们可以使用它来开始监听媒体查询以获取相关更改。一旦监听，#4 #的“更改”事件将在这些媒体查询开始或停止匹配浏览器的媒体条件时触发，例如，当用户将浏览器调整为不同大小时可能会发生这种情况。 When any of the media queries inside the video fire a change event, check if the currently playing video source is coming from a source element prior to the source element whose media just changed. If it is, then we can ignore that particular media change because any sources after the source that’s currently playing are irrelevant to selection. On the other hand, if the currently playing source of the video happens to be the source whose media did just change (presumably by no longer matching), then we should instruct the video element to load again (using video.load()) using its native selection to find the best source.\n当视频中的任何媒体查询触发更改事件时，检查当前播放的视频源是否来自媒体刚刚更改的 source 元素之前的 source 元素。如果是，那么我们可以忽略特定的媒体更改，因为当前正在播放的源之后的任何源都与选择无关。另一方面，如果当前播放的视频源恰好是其媒体刚刚改变的源（可能不再匹配），那么我们应该指示video元素使用其原生选择再次加载（使用 video.load() ）以找到最佳源。 That’s mostly it! 差不多就是这样！\nHere’s how that logic will be structured in the code in our component, with our connectedCallback and disconnectedCallback events applying code at opportune moments. In addition to those lifecycle events , I’ve also added 4 custom methods for my own code to use: bindMediaListeners, unbindMediaListeners, previousSiblingIsPlaying, and reloadVideo.\n下面是该逻辑在组件代码中的结构，我们的 connectedCallback 和 disconnectedCallback 事件在适当的时候应用代码。除了这些生命周期事件之外，我还为自己的代码添加了4个自定义方法：用途： bindMediaListeners 、 unbindMediaListeners 、 previousSiblingIsPlaying 和 reloadVideo 。\nI’ve replaced some of the code inside those methods below with comments that describe how it flows.\n我已经用注释替换了下面这些方法中的一些代码，这些注释描述了它是如何流动的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 \u0026lt;span\u0026gt;class\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;ResponsiveVideo\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;extends\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;HTMLElement\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;constructor\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;()\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;super\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;();\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;// upfront variables will go here\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; connectedCallback\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;()\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;video \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;querySelector\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#39;video\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;bindMediaListeners\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;();\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; disconnectedCallback\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;()\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;unbindMediaListeners\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;();\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; bindMediaListeners\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(){\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;// loop through the source elements inside this.video and set up listeners for their media queries\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;// when any of those listeners fire a change event,\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;// make sure the source element of the event is relevant using previousSiblingIsPlaying\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;// if it\u0026#39;s relevant, call reloadVideo to find a new source\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; unbindMediaListeners\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(){\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;// unbind the media query listeners\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; previousSiblingIsPlaying\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;elem\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;,\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; src\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;)\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;// a helper function that will return true or false for whether a previous source element is currently selected\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; reloadVideo\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(){\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;// capture the currentTime of the video\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;// reload the video, let the browser choose the best current source\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;// set the current time of the video to where it last was\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; customElements\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;define\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;responsive-video\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;,\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;ResponsiveVideo\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt; That was a big chunk of code, but it should give you an idea of the flow for how it works.\n这是一个很大的代码块，但它应该给你一个给予它是如何工作的流程的想法。\nCompleting the Enhancements 完成增强功能\nNext, let’s populate that scaffolding with the actual logic. Here’s our full web component code.\n接下来，让我们用实际的逻辑填充这个脚手架。这是我们完整的Web组件代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 \u0026lt;span\u0026gt;class\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;ResponsiveVideo\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;extends\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;HTMLElement\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;constructor\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;()\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;super\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;();\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;listenedMedia \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;[];\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;reloadQueued \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;false\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; connectedCallback\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;()\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;video \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;querySelector\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#39;video\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;bindMediaListeners\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;();\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; disconnectedCallback\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;()\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;unbindMediaListeners\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;();\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; bindMediaListeners\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(){\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;querySelectorAll\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#39;source\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;).\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;forEach\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;source \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;if\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;source\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;media\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;)\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;const\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; mqListener \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;()\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;if\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;source\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;media \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;===\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;video\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;currentSrc \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;||\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;!\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;previousSiblingIsPlaying\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;source\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;,\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;video\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;currentSrc\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;)\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026amp;amp;\u0026amp;amp;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;!\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;reloadQueued\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;)\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;reloadVideo\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;();\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;};\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;listenedMedia\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;push\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;({\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; media\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;:\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; source\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;media\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;,\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; handler\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;:\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; mqListener \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;});\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; window\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;matchMedia\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;source\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;media\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;).\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;addEventListener\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;change\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;,\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; mqListener\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;});\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; unbindMediaListeners\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(){\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;listenedMedia\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;forEach\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;listener \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; window\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;matchMedia\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;listener\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;media\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;).\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;removeEventListener\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;change\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;,\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; listener\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;handler\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;});\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; previousSiblingIsPlaying\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;elem\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;,\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; src\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;)\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;let\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; prevSibling \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; elem\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;while\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;elem\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;previousElementSibling\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;)\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;if\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;prevSibling\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;src \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;===\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; src\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;)\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;return\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;true\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;return\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;false\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; reloadVideo\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(){\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;reloadQueued \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;true\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;const\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; currentTime \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;video\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;currentTime\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;const\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; playState \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;video\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;playState\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;video\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;load\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;();\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;const\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; videoLoaded \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;()\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;video\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;playState \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; playState\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;video\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;currentTime \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; currentTime\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;toString\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;();\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;reloadQueued \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;false\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;video\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;removeEventListener\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;loadeddata\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;,\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; videoLoaded\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;};\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;this\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;video\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;addEventListener\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;loadeddata\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;,\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; videoLoaded\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; customElements\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;define\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;responsive-video\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;,\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;ResponsiveVideo\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt; And it works! In about 50 lines of code, we’ve used a web component to extend HTML video to make it do much more.\n而且它有效！在大约50行代码中，我们使用了一个Web组件来扩展HTML视频，使其做得更多。\nCheck out the Demo Page 查看演示页面\nYou can try a demo of this responsive video web component here.\n您可以在这里尝试这个响应式视频Web组件的演示。\nEven Responsiver Video Demo Page\nEven Responsiver视频演示页面\nBut hey! Not so fast….\n但是嘿！别这么快\u0026hellip;.\nI still have another important thing to cover before this thing is ready to ship.\n我还有一件重要的事要做在这东西准备好发货之前。\nEnhancing Reponsibly 增强责任感 As I mentioned early in the post, the behavior we added with this component is something that many folks expect to already work when they start using responsive video. While there is no current proposal or plans for implementing this in web standards and browsers (that I know of, at least), this does seem like the sort of feature that could possibly become natively supported in browsers one day. I hope it does actually!\n正如我在文章的前面提到的，我们在这个组件中添加的行为是许多人在开始使用响应式视频时期望已经工作的。虽然目前还没有在Web标准和浏览器中实现这一点的提议或计划（至少我知道），但这似乎是有一天可能在浏览器中原生支持的那种功能。我希望它确实如此！\nIf that does ever happen, I really wouldn’t want this web component to be duplicating or worse, interfering with the behavior that a browser handles itself. I’d like this web component to act as a polyfill for this behavior if it’s not already supported, but if it is supported, I want this web component to make itself obsolete.\n如果这种情况真的发生了，我真的不希望这个Web组件被复制或更糟，干扰浏览器处理自己的行为。我希望这个Web组件作为一个polyfill的行为，如果它还没有得到支持，但如果它是支持的，我希望这个Web组件，使自己过时。\nSo just to be safe, we should check if the browser handles this behavior natively before we add it ourselves.\n因此，为了安全起见，我们应该在自己添加之前检查浏览器是否能够处理此行为。\nIt’s time for a feature test!\n是时候进行功能测试了！\nWriting a Video Media Change Feature Test 编写视频媒体更改功能测试\nI created the following feature test to check whether a browser performs this media switching behavior natively. It’s somewhat similar to the test that I recently patched in the Web Platform Test suite which modern browsers run as part of their builds to ensure they support standard responsive video behavior. Except that this one tests for behavior that is not currently standard, of course.\n我创建了以下功能测试，以检查浏览器是否会执行此媒体切换行为。它有点类似于我最近在Web平台测试套件中修补的测试，现代浏览器作为其构建的一部分运行，以确保它们支持标准的响应视频行为。当然，除了这个测试目前还不是标准的行为。\nThe test returns a promise that will quickly resolve to either true or false to describe if a browser supports changing video sources after page load, when source media changes.\n该测试返回一个promise，它将快速解析为 true 或 false ，以描述浏览器是否支持在页面加载后更改视频源，当源媒体更改时。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026lt;span\u0026gt;// feature test for native video media switching media\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;const\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; videoMediaChangeSupport \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;async\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;()\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;return\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;new\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;Promise\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;resolve \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;const\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; iframe \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; document\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;createElement\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;iframe\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;const\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; video \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; document\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;createElement\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;video\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;const\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; source \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; document\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;createElement\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;source\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;const\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; mediaSource \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;new\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;MediaSource\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;();\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; mediaSource\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;addEventListener\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;sourceopen\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;,\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;()\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; resolve\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;true\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;));\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; source\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;src \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; URL\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;createObjectURL\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;mediaSource\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; source\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;media \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;(min-width:10px)\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; video\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;append\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;source\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; iframe\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;width \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;5\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; iframe\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;style\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;cssText \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;`position: absolute; visibility: hidden;`\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; document\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;documentElement\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;append\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;iframe\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; iframe\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;contentDocument\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;body\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;append\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;video\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; setTimeout\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(()\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; iframe\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;width \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;15\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;});\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; setTimeout\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(()\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;=\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;{\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; iframe\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;remove\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;();\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; resolve\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;false\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;},\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;1000\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;});\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;};\u0026lt;/span\u0026gt; In case you’re curious, the test works by creating a video element with a child source element that has a media query, and appends that video to a generated iframe which is too narrow for the media query to match. Then, it resizes the iframe so that the relevant media query will match. If the video requests the source after the iframe is resized, we can trust that the browser is already handling media switching in video, so we don’t need to apply our web component at all!\n如果你好奇的话，测试的工作原理是创建一个带有子元素 source 的 video 元素，该子元素具有一个媒体查询，并将该视频附加到生成的 iframe ，该 iframe 太窄，媒体查询无法匹配。然后，它调整iframe的大小，以便匹配相关的媒体查询。如果视频在iframe调整大小后请求源，我们可以相信浏览器已经在处理视频中的媒体切换，所以我们根本不需要应用我们的web组件！\nConditional Web Components 条件Web组件\nLastly, it’s time to re-define our web component ONLY if that feature test happens to fail. I’m calling this pattern a Conditional Web Component, because everything seems to have cool names now.\n最后，只有当功能测试失败时，才需要重新定义我们的Web组件。我将此模式称为条件Web组件，因为现在所有东西似乎都有很酷的名字。\nTo make it conditional, the last line of our component will now look like this:\n为了使它有条件，我们组件的最后一行现在看起来像这样：\n1 2 3 \u0026lt;span\u0026gt;if\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;await\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; videoMediaChangeSupport\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;()\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;===\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;false\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;){\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; customElements\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;.\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;define\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;(\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;\u0026#34;responsive-video\u0026#34;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;,\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;ResponsiveVideo\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;);\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; \u0026lt;/span\u0026gt;\u0026lt;span\u0026gt;}\u0026lt;/span\u0026gt; And again, that demo page has this latest example baked in!\n同样，演示页面有这个最新的例子！\nEven Responsiver Video Demo page\nEven Responsiver视频演示页面\nYou can browse the source here on Github if you prefer:\n如果你喜欢，你可以在Github上浏览源代码：\nResponsiveVideo.js file ResponsiveVideo.js文件\nUsing ResponsiveVideo.js 使用ResponsiveVideo.js\nThe script I’ve described is on Github, licensed open source under MIT. Feel free to use it, fork it, or send me issues to consider! And I’ll plan publish it to NPM soon as well.\n我描述的脚本在Github上，在MIT下许可开源。请随意使用它，分叉它，或发送问题给我考虑！我也会很快把它发布到NPM上。\nGithub Repo for ResponsiveVideo\nThanks! 谢谢你，谢谢 Thank you for reading. Feel free to leave a comment or reach out on Mastodon if you have ideas or questions.\n感谢您的阅读。如果你有想法或问题，请随时留下评论或联系Mastodon。\n","permalink":"https://aming.xyz/information/24-2-27web%E6%80%A7%E8%83%BD%E6%97%A5%E5%8E%86%E4%BD%BF%E7%94%A8html-web%E7%BB%84%E4%BB%B6%E6%89%A9%E5%B1%95%E5%93%8D%E5%BA%94%E5%BC%8F%E8%A7%86%E9%A2%91---web-performance-calendar-extending-responsive-video-with-html-web-components/","tags":null,"title":"Web性能日历»使用HTML Web组件扩展响应式视频 --- Web Performance Calendar » Extending Responsive Video with HTML Web Components"},{"categories":[""],"contents":"\n一位意大利摄影师，苦苦尝试了6年，终于在本月拍到了一张难以置信的照片：大教堂、山峰、月亮处于一条直线，并且地球反射的太阳光，通过长曝光，可以照亮月亮顶部。（via）\n","permalink":"https://aming.xyz/information/1/","tags":null,"title":"1"},{"categories":[""],"contents":" 基本乐理懂一些，会弹些曲子，指弹曲子像押尾、松井、eddie小哥的曲子会一些，在学校玩过乐队做过吉他手，也接过大大小小的表演，在b站和其他网站也投过一些表演和表演的视频，在做公众号，也在教身边许多朋友学习吉他。\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;证明一下不是“云吉他手”\n因为我自己是一路自学过来的，了解自学过程中会遇到的一些困难，所以想把这些基本问题的解决方法写出来，希望帮助自学吉他的朋友少走一些弯路，所以今天写了这篇文章！\n二、认识吉他，了解基本构造以及哪根手指该弹哪根弦\n这里以最常见的木吉他为例，（关于古典吉他，电吉他，贝斯等这里不再赘述)\n了解基本构造后，我们需要详细了解的就是认识琴弦和品记了 见下图\n如图，吉他弦由上到下分为654321弦。右手大拇指弹456弦，食指弹3弦，中指弹2弦，无名指弹1弦。小拇指不弹（有些指弹特殊指法会涉及到有些不同的地方，但都是极少数）画的丑，别介意。\n接下来是品记，特殊常用的琴上面一般都会 标记的 3 5 9 12品（可人工泛音）\n-\u0026mdash;\u0026mdash;-插入调音环节（之前有很多朋友评论如何调音，现在在这里推荐一个超好用的软件）\n它就是GuitarTuna 一款非常好用的调音软件，应用商店都能搜到，下面简单介绍如何使用\n看图 默认会是标准调弦，从6-1弦分别是 E A D G B E（至于基本乐理，我以后会专门写文章来讲述，尽量会给你们讲得通俗易懂一些，这里由于是更新，不作过多解释）\n然后这个样子就相当于把琴面朝着你，竖着放的状态，你只需要看到亮的部分对应调节（如图就是调节6弦，到达中间他会提示你)\n当然这个软件还可以用来特殊调弦，等以后写基本乐理的时候，一起说方法给大家！\n三、了解基础后，开始练基本功！（这里特别强调基本功尤为重要，千万不可小看，基本功是否扎实能决定你以后弹琴能够走多远，那些吉他大佬都是基本功特别扎实的）再说一点:刚开始练琴是很枯燥的，因为刚开始不能学什么曲子，要练基本功。但是只要你坚持下来，基本功扎实了，后面想学什么曲子学什么，所以坚持吧！\n（1）先开始练53231323，顾名思义对应上图的吉他弦，只是都是空弦（空弦的意思就是，左手不去按品阶，只用右手弹） 练这个是为了提高你手指的熟练度，很多新手刚开始练吉他都会出现刻意去看你的右手的问题，想去看自己的手指有没有放在对应的琴弦上面。 不要小瞧这个，你要练到不用看可以很流畅的弹出来，并且每一根手指弹完之后 可以很自然的放在对应的琴弦上面（要去找这个感觉）\n**(2)**接下来练习爬格子 ，爬格子是一项很重要的基本功！这个东西花样很多（b站随便一搜全是稀奇古怪的进阶爬格子方式）难的可以特别难，简单的也能很简单。我找了一个很基础很适合新手的爬格子的视频，希望对你有帮助。\n这里多说几句的废话: 刚开始爬格子左手要去按琴弦了，练着手会很痛因为要起茧子，老手不常弹再弹也一样会经历这个过程_。一定要坚持，不要怕痛。就像封面说的，如果你连爬格子都坚持不下来，梦该醒了，兄dei！_\n爬格子视频链接\n说几个这个阶段会遇到的小问题\n(1) 刚开始左手可能会按不紧导致弹不响，那就使劲去按别怕痛，不痛不肯起茧的！\n（2）可能左手手指跨度不够，从一品爬格子可能会按不了感觉手不够长。我们要做的就是慢慢打开手指，推荐这条视频锻炼。爬格子感觉手不够长，就别从一品开始，先从三品或五品开始，后面每天练琴再慢慢打开手指。\n四、如何认识吉他谱\n网上的吉他谱大致分为两种，我选的这张图是平凡之路的前奏。为什么选他，因为这个包含基本的和弦，和两种吉他谱的形式，旋律简单基本上都听过，很适合新手（我当初最开始也是学的这个，学会了到处显摆 哈哈哈\u0026hellip;.)\n先认识吉他谱子的两种形式\n（1）上面有和弦，下面是xxx的形式（以这张图为例）\n六线谱相当于吉他面朝你自己琴头向左横放，最下面为6弦，最上面是1弦。这种形式的谱子就是按着上面的和弦（马上讲怎么认识和弦)**只管弹标注的几弦就是了，**比如下面按着em和弦弹6 4 2 3弦。\n下图红色标注的是接拍的意思，这里是4/4拍，差不多相当于心跳一次的时间。其他节拍都是以这个为单位的，比如2/4拍就相当于半拍，比4/4拍快一半一样。还有很多不同节拍，后面写到再详细讲。\n和弦的认识\n还是以上图em和弦为例，和弦图相当于吉他面朝你竖着放，由左边向右依次是654321 根据标注的品阶 Em和弦应该中指按着5弦2品，无名指按着4弦2品。其他和弦也都这样看，关于和弦指法（一般来讲基本上按着手指的顺序来，比如食指管最左边，中指无名指管中间，小指管最边上，但这只是大多数，特殊的指法另当别论。）\n（2）上面没有和弦，琴弦上是数字的形式\n注意看下图 4 0 2 0，前面讲了六线谱由下到上是654321弦，那么弦上的数字就是 几品的意思，0则表示空弦（就是左手不按右手只用弹几弦）\n那么弹奏的时候就是中指按着3弦2品 ，无名指按着4弦4品\n完整的弹奏就应该是先按着G和弦，依次弹奏6、4、2、3弦，再左手无名指按着4弦4品，右手拨动4弦；左手不按，右手拨动3弦空弦（空弦的意思前面有）；然后左手食指按着3弦2品，右手拨动3弦；最后左手不按，右手拨动4弦空弦。\n五、了解了基本的和弦，认识六线谱之后你就可以练习平凡之路的前奏了\n这里简单说一下联系这阶段的问题 和弦转换 （首先你要熟悉这几个基本和弦的按法，然后控制你的节奏，很多人刚开始和弦转换都很不连贯手会跟不上。解决的办法就是把速度降下来，一定要慢下来!再上一个和弦快要结束的时候，脑子里快速回想下一个和弦该怎么去按，再上一个和弦结束时迅速接上去) 我专门找了和弦转换的视频，请看\n六、学习 简单技巧 ：击弦 、勾弦 、滑弦、击勾弦（这里推荐斑马斑马）揉弦\n能把平凡之路前奏弹得很流畅之后，那么恭喜你可以进入下一个阶段了。接下来你要接触更多的和弦来锻炼你的左手，但不至于太难的，可以去网上搜一写简单的谱子。这里我推荐斑马斑马前奏（我当初学的这个）因为这首曲子的前奏很全面，上面所写的每个技巧，里面都有比较具有代表性。下面附学习前奏的视频（里面会讲解技巧很详细，比我口述更容易懂)\n下面附谱 建议练前奏就行了，因为后面的弹唱很简单，难的是你弹与唱结合的连贯性，看个人的选择\n这里简单讲一下，击弦 、勾弦 、滑弦、击勾弦 在谱子里面的标识。（以斑马斑马为例)\n击弦：一般用圆滑线或在弧线中间加H代表。\n勾弦：一般用圆滑线或在弧线中间加P代表**。**\n滑弦：一般用圆滑线或在弧线中间加S代表**。**\n**击勾弦：**顾名思义就是把击弦和勾弦连起来 一般用HP代表\n**揉弦：**谱子一般不标记，是个人情感的处理，每个人的风格都不尽相同。就是左手按住弹奏的琴弦上下移动，发出一种延音。\n关于 （节拍) 可以看到我的以上标注，可以明显看出两个音之间长度相对较短。一拍的长度弹两个音一个音就是半拍，一拍长度弹四个音，每个音就是1/4拍。\n练习好这首曲子之后,可以再选择一首曲子前奏来加强这些技巧的运用。推荐贰佰的玫瑰，当然你可以自己找自己喜欢的曲子，和弦别太难就好。附谱（建议练前奏就好）接下来讲扫弦和大横按\n能看到这里说明你很不错！码字好累，大伙儿给我点个赞吧！\n七、扫弦和大横按（劝退了很多没有意志力的人）一定要坚持下来！\n（1）扫弦\n这个东西还是看视频学吧，毕竟文字描述太抽象。我当初也是自己看视频学的，要有耐心一点一点的去学东西。\n简单说几点：很多视频里讲扫弦要食指捏着大拇指扫，其实扫弦可以随意点，你的中指无名指都可以用起来一起扫，扫弦的时候也不要太刻意的去只扫谱子上面标注的几弦，真正扫弦的时候是不肯做到很精确的，扫到核心的琴弦就好了，一定要随意一点！（会让你学的更快）\n（2）大横按\n这个东西只要练会了久会觉得很简单，我看过很多新手学到这里半途而废。仅仅就因为受不了疼痛，所以练习大横按一定别怕痛！因为大横按是用整根手指的侧面去按住，一样的只要起茧子了就不痛了！\n我只能将一些自己的心得体会，视频链接放在这里，加油去学，千万不能再这里倒下了！\n这里推荐练习老男孩，为什么选择他，因为这首曲子全程扫弦，而且有大横按，曲子大家基本上都听过，我当初也学的这首 附谱\n八、入门后深一步的学习\n如果前面的都练得很熟练了，那么恭喜你。你现在也是小有成就了，接下来你要做的就是想好自己得主要路线 指弹 or 弹唱 当然两者都可以学的只是看你自己偏重学什么。我当初偏重学的指弹，上网搜一搜指弹（会让你改变对吉他的认知）\n偏重弹唱：可以多去练习自己喜欢的曲子了，练习更多的扫弦节奏，更难的指法，结合自己开始弹唱。\n偏重指弹：说实话，如果你前面的东西都能弹得特别熟练了，基本功也每天都练了。那你现在的水平也算入门了，接下来能够走多远全靠你自己钻研了！指弹又是一片新的世界，你会了解到各种指弹技巧（比如押尾曲子常用的am技巧、pm技巧）\n学指弹的曲子，我推荐一个人的视频给你看，他的指弹讲解视频是我认为全网最详细的了。(看下图) 讲解得很详细，很清晰！\n优酷或者哔哩哔哩 搜 \u0026mdash;\u0026ndash; 小小指弹\n练习指弹曲子，我推荐第一首\u0026mdash;-无题 陈亮老师的曲子，很有中国风特色。这里附上无题的教学视频.\n接下来附上，指弹基本上都会用到的技巧 am和pm技巧，无题里会用到am\n练习指弹曲子，我这里有一张练习曲目的顺序的图。详情点开仔细看，顺序仅供参考，看你自己喜欢什么。大概按着难度慢慢来，不要好高骛远，直接挑最难的去练，别去死磕。\n建议想学什么曲子，可以去小小这里对应的看相应教程学习曲子，它的教程是我这些年来看过的最详细觉得最好的了！\n关于以上我找的视频，分享的谱子。那些都是我以前自学的时候自己看的或是我觉得讲得比较好的。因为很多东西口述比较抽象，真正还是要你自己看视频一点一点的去抠细节认真学，一步一步的来。\n**最后说几句废话：**练琴是一个漫长的过程，每当你学会一首新曲子或者新旋律你都会有一种巨大的成就感，这种感觉很美妙。音乐是一种很神奇的东西，很多时候他能够在不知不觉间改变你很多，让你变得更优秀更阳光，变得有一种与众不同的气质。刚开始学琴的过程，都非常枯燥，练习基本功（特别强调一下练习到后期也不要忘了基本功！）坚持下来，你就会发现一个新的世界！\n从上大学到现在，接过了大型学校的表演，也上了很多小型晚会表演，当过学校乐队的吉他手，也靠着吉他追到了现在的女朋友，现在在知乎写自学吉他的文章，在做公众号（同名），也开始做b站up主，当初觉得难得爆炸的那些指弹曲：押尾fight、松井you and me 、river flows in you、eddie小哥的unravel、那些中国风曲子现在也都能弹、会弹了\n我说这些只是纯粹分享自学吉他的经历，我也只是个普通人，吉他这乐器真的就是越学越觉得自己懂得太少，我需要学习的地方还有很多 我也会不断进步！同时也会不断的分享吉他经验以此来帮助更多弹吉他的朋友！\n学无止境，比我厉害的人多了去了！比如就会是以后再回来看这篇回答的你！\n到了现在就想写点文章，帮助更多自学吉他的朋友，想起当初自己一个人自学没人教，走了好多弯路（想起都觉得心酸，所以想通过知乎来帮助更多的想学吉他的朋友！）\n想自学吉他的可以看看，也可以关注专栏：零基础自学吉他 会慢慢更新的~\n也可以来b站看看我的吉他视频，支持一下up主哦~哔哩哔哩 ( ゜- ゜)つロ 乾杯~ Bilibili\n创作不易（点个赞支持一下吧！）您的点赞和关注就是我坚持写下去的最大动力，感谢！\n衷心祝愿各位自学吉他的朋友都能够学有所成，加油 朋友！\n由于篇幅限制，还有很多自学吉他的方法没办法详讲，有问题欢迎随时来问哦！我一定会很耐心的给你解答的！\n公众号：小周吉他健身 了解更多吉他自学知识 （随时随地为您解答吉他相关问题）等你哦~\n","permalink":"https://aming.xyz/information/24-2-27%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%A6%82%E4%BD%95%E8%87%AA%E5%AD%A6%E5%90%89%E4%BB%96%E5%90%89%E4%BB%96%E8%87%AA%E5%AD%A6%E7%9C%8B%E8%BF%99%E4%B8%80%E7%AF%87%E5%B0%B1%E5%A4%9F%E4%BA%86%E8%B6%85%E9%95%BF%E5%B9%B2%E8%B4%A7-%E7%9F%A5%E4%B9%8E/","tags":null,"title":"零基础如何自学吉他？吉他自学看这一篇就够了！（超长干货） - 知乎"},{"categories":[""],"contents":"上一篇文章分析了几种比较实用巧妙的动图机构，这次我们就来看三种实例的，分析完后，同样还是在文章的最后放上模型下载的方式，那么下面我们就直接进入主题。\n还是先来看一下，今天要分析的有哪些机构：\n1、横移旋转联动机械手；\n2、可转向的凸轮机械手；\n3、n形轨迹凸轮机械手\n下面就开始挨个分析：\n横移旋转联动机械手\n一、还是先来说一下这个小机构的工作顺序：\n1、纵向气缸伸出，将整个机构向下推动；\n2、然后吸盘吸取产品后，纵向气缸再缩回，将整个机构拉到上面；\n3、横向气缸缩回，带着移动机构向右运动；且因为连杆的作用，使末端吸盘在移动的同时还会发生旋转；\n4、移动机构到位后，升降气缸伸出，由吸盘将产品放置到位；然后升降气缸再缩回，循环以上的动作。\n二、接下来就是分析机构：\n根据这个机械手的名称咱们就知道，它既可以横移，又可以旋转，所以我们把它分成移动部分和旋转部分来说。\n1、移动部分\n从第一张图可以看到，这个机械手具有纵向和横向移动的能力，其实这部分涉及的机构也比较简单，就是气缸推动滑块沿着滑轨移动，所以就不啰嗦了。\n2、旋转部分\n在分析旋转部分之前，我们先来看一下移动机构的细节图：\n1） 可以看到，旋转轴穿过轴承，然后上端和连杆1固定在一起，这样连杆在运动时就会带动旋转轴旋转；\n2） 吸盘连接轴穿过旋转轴（配合方式见上图），同时它们之间还有一个弹簧（弹簧放置位）；在连接轴的上端有一个固定环，起到限位的作用。\n这样连接轴不仅可以跟随旋转轴旋转，还能上下滑动，在吸盘吸取产品时可以起到作用。\n再来看一下连杆是怎么让吸盘旋转的：\n上面做了一个横向气缸在伸缩时的动图，然后我们来单独看一下连杆这部分的细节图：\n它的工作原理如下：\n1） 气缸缩回时，会将移动机构往回拉，这时候就会带着连杆1向右侧运动；\n2） 连杆1又带动连杆2运动，这时连杆2就会绕着旋转点进行转动；\n3） 连杆2旋转时，又会带着轴销处也转动，此时连杆1和吸盘旋转轴也就跟着一起转动了。\n下面再补充一个运动轨迹图会更容易理解点：\n可转向的凸轮机械手\n旋转轴带动凸轮1和凸轮2一起转动，其中凸轮2是负责夹爪上下运动的；凸轮1是负责夹爪前后运动的，而夹爪在前后运动的同时，由于连杆2和连杆3的作用，还会伴随着旋转运动。\n以上就是凸轮机械手的大致工作原理，下面咱们还是把它分成两个部分来说，一是上下运动部分；二是前后运动部分。\n一、上下运动部分\n首先我们需要知道的是：导轨、固定块以及横向移动滑块是连接在一起的；滑块是固定在框架上的。\n1、凸轮2顺时针旋转，当随动器位于凸轮的基圆部分时，导轨、固定块以及横向移动滑块处于下方；\n2、而随着凸轮2的继续旋转，随动器进入运动部分，这时导轨、固定块就开始上升；3、凸轮2不断的旋转，整个机构就会循环上升、下降的动作。\n二、前后运动部分\n首先我们需要知道的是：\n1、固定销轴是连接在框架上固定不动的，连杆1可以绕着固定销轴转动；\n2、连接板和导轨是固定在一起的；\n3、拉簧放置位是有一个拉簧的，一端固定在导轨上，一端固定在框架上，作用是为了将导轨拉回。\n这个部分的工作原理如下：\n1、凸轮1逆时针旋转，当随动器1位于基圆部分时，连接板和导轨处于被拉簧拉回的状态；\n2、当随动器1开始进入运动部分时，连杆1会被凸轮1推动着顺时针转动，而这时随动器2就会跟着推动连接板和导轨向右侧滑动。\n以上就是凸轮1让机构前进/后退的工作原理，但是别忘了夹爪在前进/后退的过程中还是伴随着旋转的，所以接下来我们再简单说一下夹爪是怎么旋转的：\n上图中的固定块是不动的，连杆3和夹爪连接轴固定在一起同时旋转。我想大家也发现了，其实这个旋转机构的原理和第一个机构中的旋转部分是一样的，所以在这里我就不再啰嗦一遍了。\n关于凸轮1和凸轮2的配合关系，就需要大家根据自己的实际使用工况进行设计了。\nn形轨迹凸轮机械手\n在分析这个机构之前，我们先来看一下它的动图：\n接下来，我们就来分析一下这个机构的动作原理：\n整个机构的工作顺序如下：\n1、驱动电机通过同步带轮机构带动凸轮1和凸轮2一起转动（凸轮1、凸轮2以及同步轮通过连接轴连在一起，一同旋转）；\n2、当凸轮1转动时，会推动随动器1运动，从而使连杆1绕着旋转点1转动，这时随动器2就会带着滑块1向上运动；当随动器1位于凸轮1的基圆部分时，拉簧1会拉着连杆1向下转动，同时滑块1就会向下运动；\n3、凸轮2转动时，推动随动器3运动，从而使连杆2绕着旋转点2转动，这时随动器4就会推着滑块2以及前面的滑动部分一起向左侧移动；\n4、最后通过调整凸轮1和凸轮2的配合关系，就可以实现末端滑动部分的n形运动轨迹。\n其实，机构中上下运动部分、前后运动部分的工作原理和第2个案例中的前后运动部分是非常相似的，所以关于这个机构上下运动、前后运动的详细工作原理大家可以参考第2个案例。\n下面主要来说一下凸轮1和凸轮2是怎么配合工作的：\n1、初始状态是这样的：\n2、当凸轮1逆时针旋转，使滑动部分向上运动到顶点：\n从上图可以看到，当凸轮1将连杆1推到最高点时，随动器3仍位于凸轮2的基圆部分。\n3、继续转动，就会使随动器3进入凸轮2的运动部分。将滑动部分推到最前端，状态如下：\n从上图可以看到，随动器1位于凸轮1运动部分，但即将进入基圆部分；随动器3刚进入凸轮2的运动部分。\n4、凸轮1继续逆时针转动，使滑动部分向下运动，状态如下：\n5、驱动电机继续转动，就会使滑动部分开始上升：\n到达顶点后，可以看到随动器3即将进入凸轮2的基圆部分。\n6、随着凸轮的转动，滑动部分在拉簧2的作用下就会往回运动：\n从上图可以看到，滑动部分缩到底，这时随动器1处于即将进入凸轮1基圆部分的状态。\n7、最后一步就是滑动部分向下运动，达到步骤1的状态。以上1-7的步骤就是整个机构运动的一个循环。\nOK，这次要分享的机构就分析完了，模型还是放到公号里，大家回复：凸轮机械手，就可以拿到下载链接了。\n我是\n，关注我查看更多优质文章。\n","permalink":"https://aming.xyz/information/24-2-27-%E6%9C%BA%E6%9E%84%E7%AF%87%E4%B8%A8%E8%BF%99%E6%AC%A1%E6%98%AF%E4%B8%89%E7%A7%8D%E5%AE%9E%E4%BE%8B%E6%9C%BA%E6%A2%B0%E6%9C%BA%E6%9E%84%E7%9A%84%E5%88%86%E6%9E%90-%E7%9F%A5%E4%B9%8E/","tags":null,"title":"机构篇丨这次是三种实例机械机构的分析 - 知乎"},{"categories":[""],"contents":"　阮德升（Đức thắng Nguyễn）是一位来自越南的工程师。自从2002年退休之后，他便一直在为机械构造制作令人惊艳的3D动画目录。\n他使用AutodeskInventor记录了超过1700种机械结构，并为每一个记录制作一部相应的动画视频，对于理解一些比较复杂和具有挑战性的结构而言，这些视频是非常珍贵的参考资料。除此之外，这些动画本身就是一系列迷人的动力学雕塑，同时具有其纯粹的美学价值。\n以下是精选的一些结构：\n1.追踪平行四边形的机械联动构造\n2.万向接头\n3.齿条齿轮构造应用\n4.行星离合器\n5.空间利用门\n6.在旋转过程中保持方向不变\n7.阿基米得氏曲线驱动机\n8.锥面摩擦变速器\n9.日内瓦结构内部\n10.将中断旋转变为连续旋转\n另外还有热心金粉为我们提供的机械动态图，简直太美了！\n神奇的家具\n加拿大安省3D视觉设计师盖瑞斯·福勒（Gareth Fowler）制作了一系列充满活力、韵律十足的超完美机械动图，不过这些机械并不是真的存在于生活中。所以它们可以无休止的运转，仿佛被困在了无限的时空循环中。以下有部分动态图金属加工微信号曾发布过，看过的金粉可以重温一下。有强迫症的朋友们不要盯着看太久哦~每一个动图都有美感，金属色！\n链传\n联轴节\n机关枪\n齿轮啮合\n这个好复杂，请大神指点\n猜猜这是啥\n直升机旋翼\n可变节气门\n计数器\n差速器\n透析仪\n自动步枪\n加特林机枪\n气门\n","permalink":"https://aming.xyz/information/24-2-27%E4%BB%A4%E4%BA%BA%E6%83%8A%E8%89%B3%E7%9A%841700%E7%A7%8D%E6%9C%BA%E6%A2%B0%E5%8E%9F%E7%90%86%E5%8A%A8%E6%80%81%E5%9B%BE-%E7%9F%A5%E4%B9%8E/","tags":null,"title":"令人惊艳的1700种机械原理动态图 - 知乎"},{"categories":[""],"contents":"","permalink":"https://aming.xyz/post/javascript/","tags":null,"title":"javascript"},{"categories":[""],"contents":"","permalink":"https://aming.xyz/post/python/","tags":null,"title":"python"},{"categories":[""],"contents":"穿戴保暖美化 衣服，鞋子，裙子\n休息 沙发，床\n玩耍 儿童乐园，电子游戏\n","permalink":"https://aming.xyz/post/%E7%94%9F%E6%B4%BB%E7%89%A9%E5%93%81/","tags":null,"title":"生活物品"},{"categories":[""],"contents":"快手带货 关注主播 (好物) 选品(小黄车截图) 截图封面 文案提取 剪印，图文成片，添加图片(裁剪小黄车截图),背景模糊 快手小店 ，搜索 商品名字 ，找不到同价位的商品，就复制商品链接搜索 添加商品，标题，话题，封面 发布 ","permalink":"https://aming.xyz/post/%E5%B9%BF%E5%91%8A/","tags":null,"title":"广告"},{"categories":[""],"contents":"生平 富兰克林的成功可以归功于：尽早培养优秀的习惯、自律、财富自由。\n① 优秀的习惯为富兰克林打好终身受益的基础，无论在学习、工作还是社交上，富兰克林都具备强大的应对能力，并且很有远见。这些积累使他一步步成为一名卓越的人——人生的成败与习惯有直接的关系。\n② 自律让富兰克林时刻抵制外界的诱惑，遵守自己的行事规范，以坚定的态度做任何事。美国独立战争时期，富兰克林长期拜访欧洲国家，甚至长期定居伦敦，但他始终站在争取美国独立的立场——自律和一个人的心灵有关，而不仅仅是身体。\n③ 财富自由让富兰克林脱离了为生计而奔波的日常事务，使他有更多精力投身到科学研究、公众事业上，也让富兰克林有更多金钱投入到慈善和捐助活动中——我们能管理现有的一切，我们才能得到更多。\n富兰克林的早年经历： 1706年1月17日，富兰克林出生于波士顿一个贫穷的家庭，家中有17个孩子，他排行第15。\n10岁前，富兰克林仅在学校学习过两年，连小学学历也没有。\n财富自由前，富兰克林的活动有：\n12岁-17岁，到哥哥的印刷厂当学徒 17岁，离开波士顿，千辛万苦（因为没钱）来到费城，找到了印刷工的工作 24岁，创办印刷厂，富兰克林由此积累了大笔财富，并开始投资实业 30岁，成为宾夕法尼亚议会秘书 34岁，通过印刷生意，富兰克林已成为北美北部最富有的人之一 42岁，富兰克林实现了财务自由\n财富自由后，富兰克林更多地参与到公众事业、外交活动中： 他是费城的副邮政局长、北美殖民地邮政总局长、宾夕法尼亚议会议员、费城国民自卫军指挥官 50-60岁间，富兰克林作为北美殖民地代表到英国谈判，他也多次到访法国、荷兰、德国等国家 70岁时，富兰克林成为美国驻法国大使（1776–1785年），他是美国第一位驻外大使 71岁时，富兰克林协助起草《独立宣言》，也是《独立宣言》的签署人之一 81岁时，富兰克林又成为制宪会议（Constitutional Convention）代表，参与到制定美国宪法的工作中\n","permalink":"https://aming.xyz/post/%E5%AF%8C%E5%85%B0%E5%85%8B%E6%9E%97/","tags":null,"title":"富兰克林"},{"categories":["科学"],"contents":"计算机科学： 计算机越来越智能化，懂得越来越多，用来代替或超越人所提供的能力。\n大数据：世界上的 任何状态 都进行信息化，网络化。\n生物科学 治病 寿命 基因 ","permalink":"https://aming.xyz/post/%E6%9C%AA%E6%9D%A5/","tags":null,"title":"科技发展趋向"},{"categories":["技术"],"contents":" 把计算机 软件，作为日常的物品，软件是计算机的灵魂。 人们研究社会存在的基础，然后创建规则规范应用，就是科学。\n计算机的圆 开始计算-结束\n产品就是生活中的用品，就是免费不用钱。\n定义：一种形式化的机器，辅助工作的工具 \u0026ndash;计算机，是可供计算的机器，现在使用的是可编程的计算机，而且应用在不同领域，不光用来数值计算，还有娱乐。\u0026ndash;\n所以，现代计算机更多的作为虚拟机。 虚拟物中，有山有水，有船，有树，就像橡皮泥捏的一个个东西一样，在计算机中飘荡。\n编码 信息传递认知，新闻。对信息编码，计算机要处理这种编码信息。\n编码的方式:\n书写文字 (write word) 口语 (speech ,speak word) 手语 (聋哑人) 布莱叶盲文（盲人） 电报 经过莫尔斯二进制编码后，可以 用 滴~ ，滴 长短不同的声音表示 1，0 ，进行信息的传递。\n逻辑运算 逻辑运算，布尔运算 ，对 编码（二进制） 运算\n电路的 串联，并联 可以处理 布尔运算中的 逻辑与（\u0026amp;） 和 逻辑或 （|）\n存储器 电容，光盘，磁盘\n自动操作 (软件 + 代码解释器) 自动操作 要用到 代码解释器 和时钟 ,还有软件，软件是计算机的灵魂，没软件计算机就是一个僵尸，不会动。\n操作系统 （自动化） 语言 算法处理各种问题，除了个别 如关机算法的东西。\n图形化 (点阵显示器) 交互方式 更人性化了\n网络 计算机联网后，可以远距离传递信息。\n网络程序：处理远程信息的软件\n","permalink":"https://aming.xyz/post/%E8%AE%A1%E6%9C%BA/","tags":null,"title":"计算机"},{"categories":[""],"contents":"反思 我以前看书，看视频的学习方法是错误的，我没有把自己代入进去，没有与学习之物互动，缺少动手，学习就要多交互。\n说到交互，我做人也是错误的，我对于我个人，是主体，要主动参与执行。\n我面对实践，主要的心理障碍是恐惧，然后就是懒惰，但人就是社会性，任何生物都是社会性的，该主动就主动，一直被动的是无机物，植物都是主动的。\n","permalink":"https://aming.xyz/post/%E5%AD%A6%E4%B9%A0/","tags":null,"title":"学习"},{"categories":["习惯"],"contents":"习惯：在行动前先设定目标 把目标写进备忘录 将个人目标融入团队目标 制定工作计划 如: 我的 金钱 目标：________ 何时完成？________\n如果能把自己的工作任务清楚地写下来，便能很好地进行自我管理，同时使得工作条理化，个人的能力得到很大的提高。\n习惯： 要事第一 将重要的事情放在第一位进行处理 做最重要的事，而非最容易的事 习惯3： 优化时间管理 重视时间的价值\n你珍惜生命吗？那么就请珍惜时间吧，因为生命是由时间累积起来的。\n时间就是价值，时间能用来挣钱 假如一个人杀死一头能下崽的母猪，也就是毁灭了它所有的后代，甚至它的子子孙孙。假如谁消灭了5个先令的金钱，那样就等于消灭了它所有能产生的价值。换句话说，可能毁掉了一座金山。\n揪出“时间窃贼”\n找东西 应对方法：不用的东西扔掉，不扔掉的东西分门别类保管。 懒惰 应对方法： 使用日程安排簿，在家居之外的地方工作。 时断时续 应对方法：在清晨的大段时间内工作 拖拖拉拉 活用零碎时间 零碎时间 是个人最重要的成长时间。\n习惯7. 正确地做事 复利 找对方法，莫让功劳变苦劳 追求高效能，而非高效率 投资和股票市场。 投资好的资产会增长。 创业 知识和技能 房地产租金 版权和专利 网络和数字资产 拥有数字资产，如加密货币、域名、数字收藏品等 ","permalink":"https://aming.xyz/post/%E9%AB%98%E6%95%88%E4%B9%A0%E6%83%AF/","tags":null,"title":"高效能士的习惯"},{"categories":["人"],"contents":"人生的圆 出生 - 死亡\n人的生长发育 人： 生老病死 人的细胞里面有计时器吧，多少时间后人就死了。 人与自然 人与社会 外圆内方 社会是一个竞争的环境，产品竞争，在一个领域出彩就好 社会经济与分工 男人 做男人要有自己的博客 有自己的事业 有自己的家庭 人的情绪 人有喜怒哀乐，受环境影响，不同情绪不同行为\n开心好做事，做事也开心\n消极情绪会消耗精神，浪费时间，毫无意义\n处事原则 奉献（爱），利他，才能利己\n就像力一样，作用是相互的，朋友多好资助\n","permalink":"https://aming.xyz/post/%E4%BA%BA/","tags":null,"title":"人"},{"categories":["物理"],"contents":"基础物理 共24章，包括力学、相对论、振动与波动、流体、热力学等内容，其姊《基础物理Ⅱ》\n原子 原子里是另一个宇宙\n热力学 原子运动\n温度计，测量原子运动量的工具 红外测量仪\n时空 时空弯曲（引力）没能使物体相互聚集，现在是相互远离。\n","permalink":"https://aming.xyz/post/%E7%89%A9%E4%BD%93/","tags":null,"title":"物理"},{"categories":["营销"],"contents":"寻找市场 给有需求的人推销他要的东西。\n影响力 影响力的六个原则属于现代应用传播学中的一部分，是关于“说服”技巧的理论，通常会大幅的应用在我们所有的言销、销售、推广活动当中。\n互惠性 解释：人对于别人的思惠，通常会觉得有责任或有义务进行回报。 2.稀缺性 解释：当一个东西或者一项事物，它获得的机会越少的时候，人就越想得到。通俗的理解：“物以稀为贵”\n稀缺性被大量的应用在，互联网饥饿言销上面，动不动就是2分钟被疯抢光等等这类标题。\n3.权威性 解释：人们总是通过服从权威的方式来寻找到实现行动的捷径。\n例如：现在很多的公司都用自己的CEO为品牌代言、去直播带货、例如药店营业员会穿着和医生一样的白大褂，这写形式都使用到了权威性的特点。\n4.—致性 解释：一旦我们作出了某个决定或选择了某种立场，就会面对来自个人和外部的压力，迫使我们的言行与它保持一致。\n例如：在销售场景中，销售人员会跟你讲优惠力度有多大，而且是今年最大的优惠，会追使你认可这个优惠力度，当价认可了这个优惠力度后，如果你不购买，你就感觉到自己“打脸”这种心里现象。\n偏好性 解释：大多数人总是更容易答应自己认识和喜爱的人所提出的要求。例如互联网大量运用的邀请机制、分享机制，拼多多砍一刀等等。\n共识性 解释：人们会仿效与其相似的人的做法。\n例如：某个运动品牌专属为你喜爱的球星设计款球鞋，基于你对运动的热爱和对球星的认同和喜爱，你会去选择和他买同款的球鞋，这就是共实现原则的体系。\n","permalink":"https://aming.xyz/post/%E8%90%A5%E9%94%80/","tags":null,"title":"营销"},{"categories":["数学"],"contents":"虚空的数字，居然有实体标记( 阿拉伯数字 )，还有各种场景的运用\n数学，数字计算，当要进行精确设计时，需要测量，并使用数字进行计算。\n数学的继承 托勒密 亚里士多德 牛顿 高斯 艾舍尔 （几何绘画）\n大数字的表示 无穷大 ∞\n勾股定理与直角三角形 空间 坐标，角坐标，极坐标\n拓扑 : 点，线，面\n函数 表示物质间作用后的同等关系\n复数 复数可以用 一个数字 表示两个值的坐标\n","permalink":"https://aming.xyz/post/%E6%95%B0%E5%AD%97/","tags":null,"title":"数学"},{"categories":["人生"],"contents":"\n人生选择 富兰克林做了 印刷的职业，我还是 做个程序员的职业吧，也是有前景的，做自己的项目。\n人生目标，做程序员，做自己的项目\n便签纸 simple stickly note 看书要做标记\n专注 研究 人生，科技 ，经济，家庭 4个话题 把 上面4个话题的资讯都放在 info 文件夹 穷困 穷困，别把自己困住了，别给自己围城\n世界上有不变的真理吗？人的消费习惯一直在改变，更优雅，艺术，我就是测试者,是计算机程序使用高效的测试者,语言应用的测试者。\n生命 人的生命是一个数字，365 * 60 天，生命的周期结束，人会死亡消失。\n人与人之间的关系？ 人与人之间是合作关系？\n与家人 与朋友 与同事 与社会人 什么样的人生有意义 人的意义是为自己过好的生活。\n成长，修养，修炼的人生有意义。\n生活的意义是什么 观点1 人活着，对社会来说，是一颗机器上的螺丝钉， 没用了会被新的替代。 所以人要融入社会，做那个螺丝钉，因为现在的发展都是继承前人而来的。 人活着，对自己来说，是做好那颗螺丝钉。 延续人类物种，这个意义好像太高尚了 😂\n两性差异的处理方式: 合作（婚姻），繁衍（带小孩）\n灵与肉的关系是什么 深呼吸25次可以提高专注力\n起来走走，细细观察能找到灵感\n心灵与肉体 心灵与肉体，哪个控制哪个呢？ 相当于计算机中软件和硬件一样，是为一体才有意义，但心灵控制肉体的方向，肉体会有反馈给心灵。\n自卑感和优越感 自卑感是大部分人面对危险是产生的恐惧感，而外在表象却不同。\n自律与厌恶？人性是什么？ 人的默认行为是什么？勤劳和懒惰是思想还是习惯造成的？是消极情绪造成的吗？还是因为某种行为，人自身产生的抗体？\n人的行为和习惯往往是多种因素的综合结果，包括思想、价值观、经历、环境等。因此，人的默认行为和勤劳与懒惰的倾向可能是个体差异的体现，而不是简单地归因于某种行为或抗体的产生。\n职业规划 认识自己 认识行业 认识职业类型 选择行业和职业 确认并拆分你的职业目标 梳理计划并执行 事情分轻重缓急 要记录时间 分析时间花在哪里了 要用认长处 避免短处\n快速恢复精力 想要快速恢复精力，需要进行休息，下面是提供一些方法：\n开窗眺望，倾听 大自然的声音，人的对话，鸟的对话\n冥想\n干家务活、收拾房间\n小运动、找人打球、伸展拉伸\n床上休息，做白日梦\n人生一直在变化 人生一直在变，工作调动，职业规划，婚姻状态，家庭都是在变动的。\n自己的思维要活跃些，精明些。\n家庭 家庭：家庭里的成员都是亲人。\n平庸 (躺平，平凡) 1.接受父母平庸 2.接受自己平庸 3.接受孩子平庸\n静以修身，俭以养德。\n如果可以的话，你想成为什么样的人？” “一个成功的人，比较有钱，能做到自己想做的事”\n“如果可以的话，你想做什么？” “我想做慈善、画画、练字、旅游”\n“如果可以的话，你期望几岁可以实现愿望？” “40岁就可以了”\n“那你需要在这之前做些什么？” “成为有权威的人才能够帮助别人，有资源才有机会”\n“那怎样才能成为权威的人，才能有资源？” “在行业里面积累实战的经验”\n“那个方式才可以积累实战的经验？” “实习”\n人生认知 个人发展：包括情绪管理、时间管理、沟通技巧、领导力等。《情商》（作者：丹尼尔·戈尔曼）、《精力管理》（作者：扬·洛赫哈斯）都是不错的选择。\n金融和投资：了解个人财务管理、投资理念等内容，例如《富爸爸穷爸爸》（作者：罗伯特·清崎）、《股票大作手回忆录》（作者：杰西·利弗莫尔）。\n历史与人文：了解世界各个领域的历史、文化、哲学等，比如《人类简史》（作者：尤瓦尔·赫拉利）、《思考，快与慢》（作者：丹尼尔·康曼）。\n科学与技术：关于科学、技术、人工智能、生物学等方面的书籍，例如《人类简史》（作者：尤瓦尔·赫拉利）和《未来简史》（作者：尤瓦尔·赫拉利）。\n健康与心理：了解身心健康、心理学等内容，《人类简史》（作者：尤瓦尔·赫拉利）和《未来简史》（作者：尤瓦尔·赫拉利）都包含这方面的内容。\n","permalink":"https://aming.xyz/post/%E4%BA%BA%E4%B8%96%E9%97%B4/","tags":null,"title":"人生抉择"},{"categories":null,"contents":"关于 本站启用标题搜索，按键 Ctrl + / 可以搜索文章标题。 联系方式 微信: hanyudeye 迷茫 我在找寻真理吗？能找到吗？\n自己没能力总结出复杂的结论，思维不再活跃。\n我不是我？\n抽象的文字理论！\n想象图像的结论。\n想象未来的一种创新，创造。\n认知 做一个男人要完成的义务 一个男人要做的事情\n有自己的博客 (可以发表自己的观点，如果文章有价值，有人会转载) 有自己的事业 有自己的家庭 ","permalink":"https://aming.xyz/about/","tags":null,"title":"关于"},{"categories":["科普"],"contents":"人工智能，是我思想的财富 经济 经济就是财务，经济学研究如何创造财富。\n但你也会遇到很小气的人，不接受需求，不愿意付费。\n对牛羊而言，一片草地也是经济，牛羊有需求也会付费。\n有价值的人造物。 人力，服务也是一种经济\n价格波动是价格因生产成本和供求关系(商品数量)而上下涨落的现象\n个人生产力的低下导致个人贫穷\n经济学 (研究人类形象的一种形式) 经济学是研究人在日常生活事务中的活动和思考等行为，主要以货币为主。\n研究欲望、憧憬和人类本性。\n宏观经济调节 因为市场有些滞后和未知性，可能造出来的东西太多或者没人用，所以要进行一些经济策略。\n供需(市场) 东西多了就不要造了\n税率 政府用来调节供需的\n产品 一个产品，面向的客户，有浅度使用客户，也有深度客户，所以产品要面向多层次用户开发。\n","permalink":"https://aming.xyz/post/%E7%BB%8F%E6%B5%8E/","tags":["经济"],"title":"经济"},{"categories":null,"contents":"Featured 特色\nWhy CPU Knowledge Is No Longer Enough 为什么CPU知识不再足够\nIn today\u0026rsquo;s AI age, the majority of developers train in the CPU way. This knowledge has been part of our academics as well, so it\u0026rsquo;s obvious to think and problem-solve in a CPU-oriented way.\n在当今的AI时代，大多数开发人员都是以CPU的方式进行培训的。这些知识也是我们学术的一部分，所以很明显，以面向CPU的方式思考和解决问题。\nHowever, the problem with CPUs is that they rely on a sequential architecture. In today\u0026rsquo;s world, where we are dependent on numerous parallel tasks, CPUs are unable to work well in these scenarios.\n然而，CPU的问题在于它们依赖于顺序架构。在当今世界，我们依赖于许多并行任务，CPU无法在这些场景中正常工作。\nSome problems faced by developers include:\n开发人员面临的一些问题包括：\nExecuting Parallel Tasks 执行并行任务\nCPUs traditionally operate linearly, executing one instruction at a time. This limitation stems from the fact that CPUs typically feature a few powerful cores optimized for single-threaded performance.\nCPU传统上是线性运行的，每次执行一条指令。这种限制源于CPU通常具有几个针对单线程性能进行优化的强大内核。\nWhen faced with multiple tasks, a CPU allocates its resources to address each task one after the other, leading to a sequential execution of instructions. This approach becomes inefficient in scenarios where numerous tasks need simultaneous attention.\n当面对多个任务时，CPU分配其资源以一个接一个地处理每个任务，从而导致指令的顺序执行。这种方法在需要同时关注多个任务的情况下变得低效。\nWhile we make efforts to enhance CPU performance through techniques like multi-threading, the fundamental design philosophy of CPUs prioritizes sequential execution.\n虽然我们努力通过多线程等技术来增强CPU性能，但CPU的基本设计理念优先考虑顺序执行。\nRunning AI Models Efficiently 高效运行AI模型\nAI models, employing advanced architectures like transformers, leverage parallel processing to enhance performance. Unlike older recurrent neural networks (RNNs) that operate sequentially, modern transformers such as GPT can concurrently process multiple words, increasing efficiency and capability in training. Because when we train in parallel, it will result in bigger models, and bigger models will yield better outputs.\n人工智能模型采用变压器等先进架构，利用并行处理来提高性能。与按顺序操作的旧递归神经网络（RNN）不同，GPT等现代转换器可以同时处理多个单词，从而提高训练效率和能力。因为当我们并行训练时，它会导致更大的模型，而更大的模型会产生更好的输出。\nThe concept of parallelism extends beyond natural language processing to other domains like image recognition. For instance, AlexNet, an architecture in image recognition, demonstrates the power of parallel processing by processing different parts of an image simultaneously, allowing for accurate pattern identification.\n并行性的概念从自然语言处理扩展到其他领域，如图像识别。例如，AlexNet是一种图像识别架构，它通过同时处理图像的不同部分来展示并行处理的能力，从而实现准确的模式识别。\nHowever, CPUs, designed with a focus on single-threaded performance, struggle to fully exploit parallel processing potential. They face difficulties efficiently distributing and executing the numerous parallel computations required for intricate AI models.\n然而，CPU设计的重点是单线程性能，努力充分利用并行处理的潜力。他们面临着有效分配和执行复杂AI模型所需的大量并行计算的困难。\nAs a result, the development of GPUs has become prevalent to address the specific needs of parallel processing in AI applications, unlocking higher efficiency and faster computation.\n因此，GPU的开发已经变得普遍，以解决AI应用中并行处理的特定需求，从而实现更高的效率和更快的计算。\nHow GPU Driven Development Solves These Issues GPU驱动开发如何解决这些问题\nMassive Parallelism With GPU Cores\nGPU核心的大规模并行化\nEngineers design GPUs with smaller, highly specialized cores compared to the larger, more powerful cores found in CPUs. This architecture allows GPUs to execute a multitude of parallel tasks simultaneously.\n工程师们设计的GPU具有更小、高度专业化的内核，而CPU中的内核则更大、更强大。这种架构允许GPU同时执行多个并行任务。\nThe high number of cores in a GPU are well-suited for workloads depending on parallelism, such as graphics rendering and complex mathematical computations.\nGPU中的大量内核非常适合依赖于并行性的工作负载，例如图形渲染和复杂的数学计算。\nWe will soon demonstrate how using GPU parallelism can reduce the time taken for complex tasks.\n我们将很快演示如何使用GPU并行性来减少复杂任务所需的时间。\nParallelism Used In AI Models\n人工智能模型中的相似性\nAI models, particularly those built on deep learning frameworks like TensorFlow, exhibit a high degree of parallelism. Neural network training involves numerous matrix operations, and GPUs, with their expansive core count, excel in parallelizing these operations. TensorFlow, along with other popular deep learning frameworks, optimizes to leverage GPU power for accelerating model training and inference.\n人工智能模型，特别是那些建立在TensorFlow等深度学习框架上的模型，表现出高度的并行性。神经网络训练涉及大量矩阵运算，而GPU凭借其庞大的核心数量，擅长并行处理这些运算。TensorFlow与其他流行的深度学习框架沿着进行了优化，以利用GPU的能力来加速模型训练和推理。\nWe will show a demo soon how to train a neural network using the power of the GPU.\n我们将很快展示如何使用GPU的强大功能训练神经网络的演示。\nCPUs Vs GPUs: What’s the Difference? CPU VS GPU：有什么区别？\nCPU Sequential Architecture 顺序架构\nCentral Processing Units (CPUs) are designed with a focus on sequential processing. They excel at executing a single set of instructions linearly.\n中央处理器（CPU）的设计重点是顺序处理。他们擅长线性地执行一组指令。\nCPUs are optimized for tasks that require high single-threaded performance, such as\nCPU针对需要高单线程性能的任务进行了优化，例如\nGeneral-purpose computing\n通用计算 System operations 系统操作 Handling complex algorithms that involve conditional branching\n处理涉及条件分支的复杂算法 Limited Cores For Parallel Tasks\n并行任务的有限内核\nCPUs feature a smaller number of cores, often in the range of 2-16 cores in consumer-grade processors. Each core is capable of handling its own set of instructions independently.\nCPU的核心数量较少，在消费级处理器中通常为2-16个核心。每个核心都能够独立处理自己的指令集。\nGPU Parallelized Architecture\n企业化建筑\nGraphics Processing Units (GPUs) are designed with a parallel architecture, making them highly efficient for parallel processing tasks.\n图形处理单元（GPU）采用并行架构设计，可高效执行并行处理任务。\nThis is beneficial for\n这有利于\nRendering graphics 渲染图形 Performing complex mathematical calculations\n进行复杂的数学计算 Running parallelizable algorithms\n运行可并行化算法 GPUs handle multiple tasks simultaneously by breaking them into smaller, parallel sub-tasks.\nThousands Of Cores For Parallel Tasks\nUnlike CPUs, GPUs boast a significantly larger number of cores, often numbering in the thousands. These cores are organized into streaming multiprocessors (SMs) or similar structures.\nThe abundance of cores allows GPUs to process a massive amount of data concurrently, making them well-suited for parallelisable tasks, such as image and video processing, deep learning, and scientific simulations.\nAWS GPU Instances: A Beginner\u0026rsquo;s Guide Amazon Web Services (AWS) offers a variety of GPU instances used for things like machine learning.\nHere are the different types of AWS GPU instances and their use cases:\nGeneral-Purpose Gpu Instances\nP3 and P4 instances serve as versatile general-purpose GPU instances, well-suited for a broad spectrum of workloads.\nThese include machine learning training and inference, image processing, and video encoding. Their balanced capabilities make them a solid choice for diverse computational tasks.\nPricing: The p3.2xlarge instance costs $3.06 per hour.\nThis provides 1 NVIDIA Tesla V100 GPU of 16 GB GPU memory\nInference-optimized GPU instances\nInference is the process of running live data through a trained AI model to make a prediction or solve a task.\nP5 and Inf1 instances specifically cater to machine learning inference, excelling in scenarios where low latency and cost efficiency are essential.\nPricing: the p5.48xlarge instance costs $98.32 per hour.\nThis provides 8 NVIDIA H100 GPUs of 80 GB memory each, totalling upto 640 GB Video Memory.\nGraphics-optimized GPU instances\nG4 instances instances are engineered to handle graphics-intensive tasks.\nA video game developer might use a G4 instance to render 3D graphics for a video game.\nPricing: g4dn.xlarge costs $0.526 to run per hour.\nUses 1 NVIDIA T4 GPU of 16 GB Memory.\nManaged GPU Instances\nAmazon SageMaker is a managed service for machine learning. It provides access to a variety of GPU-powered instances, including P3, P4, and P5 instances.\nSageMaker is a good choice for organizations that wants to begin machine learning easily without having to manage the underlying infrastructure.\nPricing of Amazon Sagemaker\nUsing Nvidia\u0026rsquo;s CUDA for GPU-Driven Development What Is Cuda? CUDA is a parallel computing platform and programming model developed by NVIDIA, enabling developers to accelerate their applications by harnessing the power of GPU accelerators.\nThe Practical examples in the demo will use CUDA.\nHow to Setup Cuda on Your Machine To setup CUDA on your machine you can follow these steps.\nDownload CUDA\nFrom the above link download the base installer as well as the driver installer\n从上面的链接下载基本安装程序以及驱动程序安装程序\nGo to .bashrc in home folder\n转到主文件夹中的.bashrc\nAdd the following lines below\n在下面添加以下行\nexport PATH=\u0026quot;/usr/local/cuda-12.3/bin:$PATH\u0026quot;\nexport LD_LIBRARY_PATH=\u0026quot;/usr/local/cuda-12.3/lib64:$LD_LIBRARY_PATH\u0026quot;\nExecute the following commands\n执行以下命令\nsudo apt-get install cuda-toolkit\nsudo apt-get install nvidia-gds\nReboot the system for the changes to take effect\n重新启动系统以使更改生效\nBasic Commands to Use 要使用的基本命令\nOnce you have CUDA installed, here are some helpful commands.\n一旦你安装了CUDA，这里有一些有用的命令。\nlspci | grep VGA\nThe purpose of this command is to identify and list the GPUs in your system.此命令的目的是识别和列出系统中的GPU。 nvidia-smi\nIt stands for \u0026ldquo;NVIDIA System Management Interface\u0026rdquo; It provides detailed information about the NVIDIA GPUs in your system, including utilization, temperature, memory usage and more.\n它代表“NVIDIA系统管理接口”它提供有关系统中NVIDIA GPU的详细信息，包括利用率、温度、内存使用等。\nsudo lshw -C display\nThe purpose is to provide detailed information about the display controllers in your system, including graphics cards.目的是提供有关系统中显示控制器（包括图形卡）的详细信息。 inxi -G\nThis command provides information about the graphics subsystem, including details about the GPU and the display.此命令提供有关图形子系统的信息，包括有关GPU和显示器的详细信息。 sudo hwinfo --gfxcard\nIts purpose is to obtain detailed information about the graphics cards in your system.\n其目的是获取有关系统中图形卡的详细信息。\nGet Started with the Cuda Framework Cuda框架入门\nAs we have installed the CUDA Framework, let\u0026rsquo;s start executing operations that showcases its functionality.\n既然我们已经安装了CUDA框架，让我们开始执行展示其功能的操作。\nArray Addition Problem 数组加法问题 A suitable problem to demonstrate the parallelization of GPUs is the Array addition problem.\n演示GPU并行化的一个合适的问题是数组加法问题。\nConsider the following arrays:\n考虑以下数组：\nArray A = [1,2,3,4,5,6]\n数组A = [1，2，3，4，5，6]\nArray B = [7,8,9,10,11,12]\n数组B = [7，8，9，10，11，12]\nWe need to store the sum of each element and store it in Array C.\n我们需要存储每个元素的和，并将其存储在数组C中。\nLike C = [1+7,2+8,3+9,4+10,5+11,6+12] = [8,10,12,14,16,18]\n如C = [1+ 7，2 + 8，3 + 9，4 + 10，5 + 11，6 +12] = [8，10，12，14，16，18]\nIf the CPU is to execute such operation, it would be executing the operation like the below code.\n如果CPU要执行这样的操作，它将像下面的代码一样执行操作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include \u0026lt;stdio.h\u0026gt; int a[] = {1,2,3,4,5,6}; int b[] = {7,8,9,10,11,12}; int c[6]; int main() { int N = 6; // Number of elements for (int i = 0; i \u0026lt; N; i++) { c[i] = a[i] + b[i]; } for (int i = 0; i \u0026lt; N; i++) { printf(\u0026#34;c[%d] = %d\u0026#34;, i, c[i]); } return 0; } The previous method involves traversing the array elements one by one and performing the additions sequentially. However, when dealing with a substantial volume of numbers, this approach becomes sluggish due to its sequential nature.\n前面的方法涉及逐个遍历数组元素并顺序执行加法。然而，当处理大量的数字时，这种方法由于其顺序性而变得缓慢。\nTo address this limitation, GPUs offer a solution by parallelizing the addition process. Unlike CPUs, which execute operations one after the other, GPUs can concurrently perform multiple additions.\n为了解决这个问题，GPU提供了一个并行加法过程的解决方案。与一个接一个地执行操作的CPU不同，GPU可以同时执行多个加法。\nFor instance, the operations 1+7, 2+8, 3+9, 4+10, 5+11 and 6+12 can be executed simultaneously through parallelization with the assistance of a GPU.\n例如，操作1+7、2+8、3+9、4+10、5+11和6+12可以在GPU的辅助下通过并行化同时执行。\nUtilizing CUDA, the code to achieve this parallelized addition is as follows:\n利用CUDA，实现这种并行加法的代码如下：\nWe will use a kernel file (.cu) for the demonstration.\n我们将使用内核文件（.cu）进行演示。\nLet\u0026rsquo;s go through the code one by one.\n让我们一个一个地检查代码。\n1 2 3 4 5 6 __global__ void vectorAdd(int* a, int* b, int* c) { int i = threadIdx.x; c[i] = a[i] + b[i]; return; } __global__ specifier indicates that this function is a kernel function, which will be called on the GPU.\n__global__ 说明符表示此函数是内核函数，将在GPU上调用。\nvectorAdd takes three integer pointers (a, b, and c) as arguments, representing vectors to be added.\nvectorAdd 将三个整数指针（a、B和c）作为参数，表示要相加的向量。\nthreadIdx.x retrieves the index of the current thread (in a one-dimensional grid).\nthreadIdx.x 检索当前线程的索引（在一维网格中）。\nThe sum of the corresponding elements from vectors a and b is stored in vector c.\n来自向量a和B的对应元素的和存储在向量c中。\nNow lets go through the main function.\n现在让我们来看看main函数。\nPointers cudaA, cudaB and cudaC are created to point to memory on the GPU.\n创建指针 cudaA 、 cudaB 和 cudaC 以指向GPU上的存储器。\n1 2 3 4 5 6 7 8 9 // Uses CUDA to use functions that parallelly calculates the addition int main(){ int a[] = {1,2,3}; int b[] = {4,5,6}; int c[sizeof(a) / sizeof(int)] = {0}; // Create pointers into the GPU int* cudaA = 0; int* cudaB = 0; int* cudaC = 0; Using cudaMalloc, memory is allocated on the GPU for the vectors cudaA, cudaB, and cudaC.\n使用 cudaMalloc ，在GPU上为向量cudaA、cudaB和cudaC分配内存。\n1 2 3 4 // Allocate memory in the GPU cudaMalloc(\u0026amp;cudaA,sizeof(a)); cudaMalloc(\u0026amp;cudaB,sizeof(b)); cudaMalloc(\u0026amp;cudaC,sizeof(c)); The content of vectors a and b is copied from the host to the GPU using cudaMemcpy.\n使用 cudaMemcpy 将向量a和B的内容从主机复制到GPU。\n1 2 3 // Copy the vectors into the gpu cudaMemcpy(cudaA, a, sizeof(a), cudaMemcpyHostToDevice); cudaMemcpy(cudaB, b, sizeof(b), cudaMemcpyHostToDevice); The kernel function vectorAdd is launched with one block and a number of threads equal to the size of the vectors.\n启动内核函数 vectorAdd 时使用一个块和与向量大小相等的线程数。\n1 2 // Launch the kernel with one block and a number of threads equal to the size of the vectors vectorAdd \u0026lt;\u0026lt;\u0026lt;1, sizeof(a) / sizeof(a[0])\u0026gt;\u0026gt;\u0026gt; (cudaA, cudaB, cudaC); The result vector cudaC is copied from the GPU back to the host.\n将结果向量 cudaC 从GPU复制回主机。\n1 2 // Copy the result vector back to the host cudaMemcpy(c, cudaC, sizeof(c), cudaMemcpyDeviceToHost); We can then print the results as usual\n然后我们可以像往常一样打印结果\n1 2 3 4 5 6 7 8 // Print the result for (int i = 0; i \u0026lt; sizeof(c) / sizeof(int); i++) { printf(\u0026#34;c[%d] = %d\u0026#34;, i, c[i]); } return 0; } For executing this code, we will use nvcc command.\n为了执行此代码，我们将使用 nvcc 命令。\nWe will get the output as\n我们将得到输出为\nHere\u0026rsquo;s the full code for your reference.\n下面是完整的代码供您参考。\nOptimize Image Generation in Python Using the GPU 使用GPU在Python中优化图像生成\nThis section explores the optimization of performance-intensive tasks, such as image generation, using GPU processing.\n本节探讨使用GPU处理优化性能密集型任务，例如图像生成。\nMandelbrot set is a mathematical construct that forms intricate visual patterns based on the behavior of specific numbers in a prescribed equation. Generating one is a resource intensive operation.\n曼德尔布罗特集是一种数学构造，它根据指定等式中特定数字的行为形成复杂的视觉模式。生成一个是资源密集型操作。\nIn the following code snippet, you can observe the conventional method of generating a Mandelbrot set using CPU processing, which is slow.\n在下面的代码片段中，您可以观察到使用CPU处理生成Mandelbrot集的传统方法，这种方法很慢。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 # Import necessary libraries from matplotlib import pyplot as plt import numpy as np from pylab import imshow, show from timeit import default_timer as timer # Function to calculate the Mandelbrot set for a given point (x, y) def mandel(x, y, max_iters): c = complex(x, y) z = 0.0j # Iterate to check if the point is in the Mandelbrot set for i in range(max_iters): z = z*z + c if (z.real*z.real + z.imag*z.imag) \u0026gt;= 4: return i # If within the maximum iterations, consider it part of the set return max_iters # Function to create the Mandelbrot fractal within a specified region def create_fractal(min_x, max_x, min_y, max_y, image, iters): height = image.shape[0] width = image.shape[1] # Calculate pixel sizes based on the specified region pixel_size_x = (max_x - min_x) / width pixel_size_y = (max_y - min_y) / height # Iterate over each pixel in the image and compute the Mandelbrot value for x in range(width): real = min_x + x * pixel_size_x for y in range(height): imag = min_y + y * pixel_size_y color = mandel(real, imag, iters) image[y, x] = color # Create a blank image array for the Mandelbrot set image = np.zeros((1024, 1536), dtype=np.uint8) # Record the start time for performance measurement start = timer() # Generate the Mandelbrot set within the specified region and iterations create_fractal(-2.0, 1.0, -1.0, 1.0, image, 20) # Calculate the time taken to create the Mandelbrot set dt = timer() - start # Print the time taken to generate the Mandelbrot set print(\u0026#34;Mandelbrot created in %f s\u0026#34; % dt) # Display the Mandelbrot set using matplotlib imshow(image) show() The above code produces the output in 4.07 seconds.\n上面的代码在 4.07 秒内产生输出。\nTo make this faster, we can parallelize the code with GPU by using Numba library, Lets see how its done.\n为了使这更快，我们可以通过使用Numba库将代码与GPU并行化，让我们看看它是如何完成的。\nWe will import Just-In-Time compilation, CUDA for GPU acceleration, and other utilities from numba\n我们将从numba导入即时编译、CUDA GPU加速和其他实用程序\n1 2 3 4 import numpy as np from numba import jit, cuda, uint32, f8, uint8 from pylab import imshow, show from timeit import default_timer as timer The @jit decorator signals Numba to perform Just-In-Time compilation, translating the Python code into machine code for improved execution speed.\n@jit decorator向Numba发出信号，执行即时编译，将Python代码转换为机器码，以提高执行速度。 1 2 3 4 5 6 7 8 9 10 @jit def mandel(x, y, max_iters): c = complex(x, y) z = 0.0j for i in range(max_iters): z = z*z + c if (z.real*z.real + z.imag*z.imag) \u0026gt;= 4: return i return max_iters mandel_gpu is a GPU-compatible version of the mandel function created using cuda.jit. This allows the mandel logic to be offloaded to the GPU.\nmandel_gpu 是使用cuda.jit创建的mandel函数的GPU兼容版本。这允许将mandel逻辑卸载到GPU。 This is done by using @cuda.jit decorator along with specifying the data types (f8 for float, uint32 for unsigned integer) for the function arguments.\n这是通过使用 @cuda.jit 装饰器沿着指定函数参数的数据类型（f8表示浮点数，uint32表示无符号整数）来完成的。 The device=True argument indicates that this function will run on the GPU.\ndevice=True 参数表示此函数将在GPU上运行。 1 mandel_gpu = cuda.jit((f8, f8, uint32), device=True)(mandel) The mandel_kernel function is defined to be executed on the CUDA GPU. It is responsible for parallelizing the Mandelbrot set generation across GPU threads.\nmandel_kernel函数被定义为在CUDA GPU上执行。它负责跨GPU线程并行化Mandelbrot集生成。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @cuda.jit((f8, f8, f8, f8, uint8[:,:], uint32)) def mandel_kernel(min_x, max_x, min_y, max_y, image, iters): height = image.shape[0] width = image.shape[1] pixel_size_x = (max_x - min_x) / width pixel_size_y = (max_y - min_y) / height startX, startY = cuda.grid(2) gridX = cuda.gridDim.x * cuda.blockDim.x gridY = cuda.gridDim.y * cuda.blockDim.y for x in range(startX, width, gridX): real = min_x + x * pixel_size_x for y in range(startY, height, gridY): imag = min_y + y * pixel_size_y image[y, x] = mandel_gpu(real, imag, iters) Now, we can use the GPU-accelerated Mandelbrot set generation in the create_fractal_gpu function. This function allocates GPU memory, launches the GPU kernel (mandel_kernel), and copies the result back to the CPU.\n现在，我们可以在create_fractal_gpu函数中使用GPU加速的Mandelbrot集生成。此函数分配GPU内存，启动GPU内核（mandel_kernel），并将结果复制回CPU。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def create_fractal_gpu(min_x, max_x, min_y, max_y, image, iters): # Step 1: Allocate GPU memory for the image d_image = cuda.to_device(image) # Step 2: Define the number of threads and blocks for GPU parallelization threadsperblock = (16, 16) blockspergrid_x = int(np.ceil(image.shape[1] / threadsperblock[0])) blockspergrid_y = int(np.ceil(image.shape[0] / threadsperblock[1])) blockspergrid = (blockspergrid_x, blockspergrid_y) # Step 3: Measure the starting time start = timer() # Step 4: Launch the GPU kernel (mandel_kernel) to calculate the Mandelbrot set on the GPU mandel_kernel[blockspergrid, threadsperblock](min_x, max_x, min_y, max_y, d_image, iters) # Step 5: Wait for the GPU to finish its work (synchronize) cuda.synchronize() # Step 6: Measure the time taken by GPU processing dt = timer() - start # Step 7: Copy the results back from GPU memory to the CPU d_image.copy_to_host(image) # Step 8: Display the Mandelbrot set image print(\u0026#34;Mandelbrot created on GPU in %f s\u0026#34; % dt) imshow(image) show() The above code gets executed in 0.0046 seconds. Which is a lot faster the CPU Based code we had earlier.\n上面的代码在 0.0046 seconds 中执行。这比我们之前使用的基于CPU的代码快得多。\nHere\u0026rsquo;s the full code for your reference.\n下面是完整的代码供您参考。\nTraining a Cat VS Dog Neural Network Using the GPU 使用GPU训练猫与狗神经网络\nOne of the hot topics we see nowadays is how GPUs are getting used in AI, So to demonstrate that we will be creating a neural network to differentiate between cats and dogs.\n我们现在看到的热门话题之一是GPU如何在AI中使用，所以为了证明我们将创建一个神经网络来区分猫和狗。\nPrerequisites 先决条件\nCUDA\nTensorflow -\u0026gt; Can be installed via pip install tensorflow[and-cuda]\nTensorflow -\u0026gt;可以通过 pip install tensorflow[and-cuda] 安装\nWe will use a data set of cats and dogs from kaggle\n我们将使用来自Kaggle的猫和狗的数据集\nOnce you have downloaded it, Unzip them, organize the pictures of cats and dogs in the training folder into different subfolders, Like so.\n一旦你下载了它，解压缩它们，组织训练文件夹中的猫和狗的图片到不同的文件夹，像这样.\nThis is the code we will use for training and using the Cat vs Dog Model.\n这是我们将用于训练和使用猫对狗模型的代码。\nThe below code uses a convolutional neural network, you can read more details about it\n下面的代码使用了卷积神经网络，你可以阅读更多关于它的细节\nImporting Libraries 图书馆\npandas and numpy for data manipulation.\npandas和numpy用于数据操作。 Sequential for creating a linear stack of layers in the neural network.\n用于在神经网络中创建线性层堆栈的顺序。 Convolution2D, MaxPooling2D, Dense, and Flatten are layers used in building the Convolutional Neural Network (CNN).\n卷积2D，MaxPooling2D，Dense和Flatten是用于构建卷积神经网络（CNN）的层。 ImageDataGenerator for real-time data augmentation during training.\nImageDataGenerator用于在训练过程中进行实时数据增强。 1 2 3 4 5 import pandas as pd import numpy as np from keras.models import Sequential from keras.layers import Convolution2D, MaxPooling2D, Dense, Flatten from keras.preprocessing.image import ImageDataGenerator Initializing the Convolutional Neural Network\n初始化卷积神经网络\n1 classifier = Sequential() Loading the data for training\n加载用于训练的数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 train_datagen = ImageDataGenerator( rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True ) test_datagen = ImageDataGenerator(rescale=1./255) training_set = train_datagen.flow_from_directory( \u0026#39;./training_set\u0026#39;, target_size=(64, 64), batch_size=32, class_mode=\u0026#39;binary\u0026#39; ) test_set = test_datagen.flow_from_directory( \u0026#39;./test_set\u0026#39;, target_size=(64, 64), batch_size=32, class_mode=\u0026#39;binary\u0026#39; ) Building the CNN Architecture\n构建CNN架构\n1 2 3 4 5 classifier.add(Convolution2D(32, 3, 3, input_shape=(64, 64, 3), activation=\u0026#39;relu\u0026#39;)) classifier.add(MaxPooling2D(pool_size=(2, 2))) classifier.add(Flatten()) classifier.add(Dense(units=128, activation=\u0026#39;relu\u0026#39;)) classifier.add(Dense(units=1, activation=\u0026#39;sigmoid\u0026#39;)) Compiling the model 编译模型\n1 classifier.compile(optimizer=\u0026#39;adam\u0026#39;, loss=\u0026#39;binary_crossentropy\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) Training the model 训练模型\n1 2 classifier.fit(training_set, epochs=25, validation_data=test_set, validation_steps=2000) classifier.save(\u0026#39;trained_model.h5\u0026#39;) Once we have trained the model, The model is stored in a .h5 file using classifier.save\n一旦我们训练了模型，模型将使用 classifier.save 存储在.h5文件中。\nIn the below code, we will use this trained_model.h5 file to recognize cats and dogs.\n在下面的代码中，我们将使用这个 trained_model.h5 文件来识别猫和狗。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import numpy as np from keras.models import load_model import keras.utils as image def predict_image(imagepath, classifier): predict = image.load_img(imagepath, target_size=(64, 64)) predict_modified = image.img_to_array(predict) predict_modified = predict_modified / 255 predict_modified = np.expand_dims(predict_modified, axis=0) result = classifier.predict(predict_modified) if result[0][0] \u0026gt;= 0.5: prediction = \u0026#39;dog\u0026#39; probability = result[0][0] print(\u0026#34;Probability = \u0026#34; + str(probability)) print(\u0026#34;Prediction = \u0026#34; + prediction) else: prediction = \u0026#39;cat\u0026#39; probability = 1 - result[0][0] print(\u0026#34;Probability = \u0026#34; + str(probability)) print(\u0026#34;Prediction = \u0026#34; + prediction) # Load the trained model loaded_classifier = load_model(\u0026#39;trained_model.h5\u0026#39;) # Example usage dog_image = \u0026#34;dog.jpg\u0026#34; predict_image(dog_image, loaded_classifier) cat_image = \u0026#34;cat.jpg\u0026#34; predict_image(cat_image, loaded_classifier) Let\u0026rsquo;s see the output让我们看看输出 Here\u0026rsquo;s the full code for your reference\n下面是完整的代码供您参考\nConclusion 结论 In the upcoming AI age, GPUs are not a thing to be ignored, We should be more aware of its capabilities.\n在即将到来的AI时代，GPU是一个不容忽视的东西，我们应该更加了解它的能力。\nAs we transition from traditional sequential algorithms to increasingly prevalent parallelized algorithms, GPUs emerge as indispensable tools that empower the acceleration of complex computations. The parallel processing prowess of GPUs is particularly advantageous in handling the massive datasets and intricate neural network architectures inherent to artificial intelligence and machine learning tasks.\n随着我们从传统的顺序算法过渡到越来越流行的并行算法，GPU成为加速复杂计算的不可或缺的工具。GPU的并行处理能力在处理人工智能和机器学习任务所固有的大规模数据集和复杂的神经网络架构方面特别有利。\nFurthermore, the role of GPUs extends beyond traditional machine learning domains, finding applications in scientific research, simulations, and data-intensive tasks. The parallel processing capabilities of GPUs have proven instrumental in addressing challenges across diverse fields, ranging from drug discovery and climate modelling to financial simulations.\n此外，GPU的作用超出了传统的机器学习领域，在科学研究、模拟和数据密集型任务中找到了应用。GPU的并行处理能力已被证明有助于解决从药物发现和气候建模到金融模拟等不同领域的挑战。\nReference 参考 Using Numba for mandelbrot generation\n使用Numba生成mandelbrot Using Convolutional Neural Networks\n使用卷积神经网络 Hackernews post\nLinkedin post Linkedin帖子\n","permalink":"https://aming.xyz/information/24-2-27ai%E6%97%B6%E4%BB%A3%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E6%9C%80%E4%BD%8E%E8%A6%81%E6%B1%82---gpu-survival-toolkit-for-the-ai-age-the-bare-minimum-every-developer-must-know/","tags":null,"title":""},{"categories":null,"contents":"软件 ","permalink":"https://aming.xyz/post/awesome-soft/","tags":null,"title":""},{"categories":null,"contents":"","permalink":"https://aming.xyz/post/awesome-%E4%B9%A6%E7%B1%8D/","tags":null,"title":""},{"categories":null,"contents":"","permalink":"https://aming.xyz/post/awesome-%E4%BA%A7%E5%93%81/","tags":null,"title":""},{"categories":null,"contents":"","permalink":"https://aming.xyz/post/awesome-%E5%AE%B6%E5%BA%AD/","tags":null,"title":""},{"categories":null,"contents":"","permalink":"https://aming.xyz/post/awesome-%E9%9F%B3%E4%B9%90/","tags":null,"title":""},{"categories":null,"contents":"日常博客，记录生活琐事\n反思 [12.22] 做比学重要的多，有时候不用学，做的过程中自然领悟了，最多配个备忘表。\n[之前] 我以前看书，看视频的学习方法是错误的，我没有把自己代入进去，没有与学习之物互动，缺少动手，学习就要多交互。\n说到交互，我做人也是错误的，我对于我个人，是主体，要主动参与执行。\n我面对实践，主要的心理障碍是恐惧，然后就是懒惰，但人就是社会性，任何生物都是社会性的，该主动就主动，一直被动的是无机物，植物都是主动的。\n其实，世上的东西，我主动了，他们会伤害我吗？除了野兽，没人伤害我，如果被动，或不动，才会受到伤害。\n","permalink":"https://aming.xyz/readme/","tags":null,"title":""}]